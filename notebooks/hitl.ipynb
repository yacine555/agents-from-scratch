{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c57479",
   "metadata": {},
   "source": [
    "# Human-in-the-Loop\n",
    "\n",
    "We've tested two different email assistant, both of which can triage emails and use tools to respond to them. But do we actually *trust* them to manage our inbox? Few would trust an AI to manage their inbox without some human oversight immediately, which is why human-in-the-loop (HITL) is a critical pattern for many agent systems.\n",
    "\n",
    "![overview-img](img/overview_hitl.png)\n",
    "\n",
    "## Goal \n",
    "\n",
    "The goal is simple: we want to add a human-in-the-loop to our email assistant so that we can review specific tool calls, like sending an email! \n",
    "\n",
    "![overview-img](img/hitl_schematic.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77003d",
   "metadata": {},
   "source": [
    "Let' see this working in practice! Then, we'll explain it in detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a082b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uuid\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from email_assistant.email_assistant_hitl import overall_workflow\n",
    "\n",
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_1 = uuid.uuid4()\n",
    "thread_config_1 = {\"configurable\": {\"thread_id\": thread_id_1}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8085d9",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call\n",
    "\n",
    "With the meeting scheduled, the agent now drafts a confirmation email to the client. The interrupt contains:\n",
    "\n",
    "1. The email tool action with recipient, subject, and proposed content\n",
    "2. The formatted email showing what will be sent\n",
    "3. The same configuration options for user response types\n",
    "\n",
    "When the user accepts, the email is sent as written. After this step, the agent marks the task as complete with the `Done` tool call, and the workflow ends. The complete message history shows all the steps taken:\n",
    "\n",
    "1. Initial email processing\n",
    "2. Calendar availability checks for both days\n",
    "3. Meeting scheduling with confirmation\n",
    "4. Email composition and sending\n",
    "5. Workflow completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_1)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31380b57",
   "metadata": {},
   "source": [
    "## LangGraph Interrupts\n",
    "\n",
    "The HITL (Human-In-The-Loop) pattern is useful for applications where decisions require human validation. LangGraph provides built-in support for this through its [interrupt mechanism](https://langchain-ai.github.io/langgraph/concepts/interrupts/), allowing us to pause execution of an agent and request human input when needed. Let's add HITL to our email assistant after specific tools are called.\n",
    "\n",
    "### Simple Interrupt Example\n",
    "\n",
    "First, let's just show a simple example for how to use the `interrupt` function. Assume we want a simple agent that can ask the user a question and then use that information. The `interrupt` function can be used for this purpose:\n",
    "\n",
    "```\n",
    "location = interrupt(ask.question)\n",
    "```\n",
    "\n",
    "When this line executes:\n",
    "1. It raises a `GraphInterrupt` exception, which pauses the graph execution\n",
    "2. It surfaces the value passed in (`ask.question`) to the client \n",
    "3. Execution stops at this point until resumed \n",
    "4. When resumed, the function returns the value provided by the human\n",
    "\n",
    "Here's a minimal example of how to implement this using `interrupt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import MessagesState, START, END, StateGraph\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Command, interrupt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    return f\"I looked up: {query}. Result: It's sunny in San Francisco.\"\n",
    "\n",
    "# We can define a tool definition for `ask_human`\n",
    "class AskHuman(BaseModel):\n",
    "    \"\"\"Ask the human a question\"\"\"\n",
    "    question: str\n",
    "\n",
    "tools = [search, AskHuman]\n",
    "tool_node = ToolNode([search])\n",
    "\n",
    "# Set up the model\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4o\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state) -> Literal[\"ask_human\", \"action\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return END\n",
    "    # If tool call is asking Human, we return that node\n",
    "    elif last_message.tool_calls[0][\"name\"] == \"AskHuman\":\n",
    "        return \"ask_human\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"action\"\n",
    "\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    message = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "def ask_human(state):\n",
    "    # Get the tool call ID \n",
    "    tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "    # Get the AskHuman schema\n",
    "    ask = AskHuman.model_validate(state[\"messages\"][-1].tool_calls[0][\"args\"])\n",
    "    # Interrupt the graph with the question from the AskHuman schema\n",
    "    location = interrupt(ask.question)\n",
    "    # Create a tool message once the user has responded with the location\n",
    "    tool_message = [{\"tool_call_id\": tool_call_id, \"type\": \"tool\", \"content\": location}]\n",
    "    return {\"messages\": tool_message}\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "workflow.add_node(\"ask_human\", ask_human)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "workflow.add_edge(START, \"agent\")\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "workflow.add_edge(\"ask_human\", \"agent\")\n",
    "\n",
    "# Set up memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "# Compile the workflow\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "# Draw the graph\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c95ee",
   "metadata": {},
   "source": [
    "Now, we ask the user where they are and look up the weather there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e56ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "messages = [{\"role\": \"user\", \"content\": \"Ask the user where they are, then look up the weather there\"}]\n",
    "for event in app.stream({\"messages\": messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253a7c2",
   "metadata": {},
   "source": [
    "You can see that our graph got interrupted inside the `ask_human` node. It is now waiting for a location to be provided. You also notice that we use the [checkpointer](https://langchain-ai.github.io/langgraph/concepts/memory/#short-term-memory) to persist the state of the graph after the interrupt. This allows us to resume execution from the same state after the human has responded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548507e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa829ec4",
   "metadata": {},
   "source": [
    "### Using Command to Resume Execution\n",
    "\n",
    "After an interrupt, we need a way to continue execution. This is where the `Command` interface comes in. [The `Command` object has several powerful capabilities](https://langchain-ai.github.io/langgraph/how-tos/command/):\n",
    "- `resume`: Provides the value to return from the interrupt call\n",
    "- `goto`: Specifies which node to route to next\n",
    "- `update`: Modifies the state before continuing execution\n",
    "- `graph`: Controls navigation between parent and child graphs\n",
    "\n",
    "In this case, the `Command` object serves two crucial purposes:\n",
    "1. It provides the value to be returned from the `interrupt` call\n",
    "2. It controls the flow of execution in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ace4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume execution with the value \"san francisco\"\n",
    "for event in app.stream(Command(resume=\"san francisco\"), config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ec291",
   "metadata": {},
   "source": [
    "## Agent Inbox\n",
    "\n",
    "While we can implement basic human-in-the-loop functionality using `interrupt` calls and `Command` responses with the SDK, as shown above, this doesn't really scale well if we want to process a large number of emails and a variety of different actions. Our email assistant requires several types of human-in-the-loop interactions:\n",
    "\n",
    "1. **Email Triage Review**:\n",
    "   - When an email is classified as \"NOTIFY,\" humans should verify this classification\n",
    "   - Users should be able to accept the classification or provide feedback on how it should be classified\n",
    "\n",
    "2. **Email Response Review**:\n",
    "   - Before sending responses to important emails, humans should review the content\n",
    "   - Users need options to edit the draft, accept it as-is, provide feedback, or reject it entirely\n",
    "\n",
    "3. **Meeting Scheduling Review**:\n",
    "   - When the assistant proposes scheduling a meeting, humans should verify the details\n",
    "   - Users should be able to modify attendees, duration, date/time before accepting\n",
    "\n",
    "In general, any significant action (sending emails, scheduling meetings) requires human approval. Some low-risk tools (like calendar availability checks) can run without interruption. Of course, this is entirely dependent on the application and the risk of the action.\n",
    "\n",
    "### Agent Inbox: A Purpose-Built HITL Interface\n",
    "\n",
    "With this in mind, we built a simple interface for human-in-the-loop called [Agent Inbox](https://github.com/langchain-ai/agent-inbox) that allows us to review and approve or reject actions taken by LangGraph agents. Agent Inbox provides:\n",
    "\n",
    "1. **Structured Interaction Types**:\n",
    "   - `accept`: Approve the agent's action and continue\n",
    "   - `edit`: Modify the agent's proposed action before execution\n",
    "   - `response`: Provide feedback or answers without editing\n",
    "   - `ignore`: Reject the agent's action entirely\n",
    "\n",
    "2. **Rich Content Display**:\n",
    "   - Render (email) content in a readable format\n",
    "   - Support markdown for structured information presentation\n",
    "\n",
    "3. **Consistent User Experience**:\n",
    "   - Notification system for pending reviews\n",
    "   - Action buttons that match the allowed interaction types\n",
    "   - Thread-based organization of agent activities\n",
    "\n",
    "4. **Easy Integration with LangGraph**:\n",
    "   - Simple connection to local or hosted LangGraph deployments\n",
    "   - Compatible with LangGraph's interrupt mechanism\n",
    "   - No complex frontend development required\n",
    "\n",
    "### Integration with LangGraph's interrupt() Function\n",
    "\n",
    "Agent Inbox integrates seamlessly with LangGraph's `interrupt()` function. The integration works like this:\n",
    "\n",
    "1. **Request Structure**: We structure an interrupt request with specific fields:\n",
    "   ```python\n",
    "   request = {\n",
    "       \"action_request\": {\n",
    "           \"action\": \"write_email\",  # Name of the tool to call\n",
    "           \"args\": {\"to\": \"john@example.com\", \"subject\": \"Meeting\", \"content\": \"...\"}  # Action parameters\n",
    "       },\n",
    "       \"config\": {\n",
    "           \"allow_ignore\": True,   # Can dismiss the action\n",
    "           \"allow_respond\": True,  # Can provide feedback\n",
    "           \"allow_edit\": True,     # Can modify the action\n",
    "           \"allow_accept\": True,   # Can approve the action\n",
    "       },\n",
    "       \"description\": \"Email content to display...\" # Context shown to the user\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **Passing to interrupt()**: We pass this request to the interrupt function:\n",
    "   ```python\n",
    "   response = interrupt([request])[0]  # Can batch multiple requests\n",
    "   ```\n",
    "\n",
    "3. **User Interaction**: Agent Inbox shows the request and collects the user's response\n",
    "\n",
    "4. **Handling Responses**: When execution resumes, we receive a structured `response`:\n",
    "   ```python\n",
    "   if response[\"type\"] == \"accept\":\n",
    "       # Execute the tool with original args\n",
    "   elif response[\"type\"] == \"edit\":\n",
    "       # Execute with edited args from response[\"args\"]\n",
    "   elif response[\"type\"] == \"ignore\":\n",
    "       # Skip execution\n",
    "   elif response[\"type\"] == \"response\":\n",
    "       # Process feedback from response[\"args\"]\n",
    "   ```\n",
    "\n",
    "This structured approach allows our email assistant to collect precise human input at critical decision points while maintaining a consistent user experience.\n",
    "\n",
    "## Email Assistant with Human-in-the-Loop\n",
    "\n",
    "Now that we understand both the interrupt mechanism and Agent Inbox, let's look at our email assistant implementation with human-in-the-loop. This implementation brings together all the concepts we've discussed:\n",
    "\n",
    "1. It uses the `interrupt` function to pause execution at key decision points\n",
    "2. It structures interrupt requests specifically for Agent Inbox\n",
    "3. It processes different response types from human reviewers\n",
    "4. It integrates these HITL capabilities into a full email processing workflow\n",
    "\n",
    "We'll instrument each of these human-in-the-loop capabilities into our email assistant. Then, in the next notebook, we'll add in memory!\n",
    "\n",
    "![overview-img](img/HITL_flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, agent_system_prompt_hitl, default_background, default_triage_instructions, default_response_preferences, default_cal_preferences\n",
    "from src.email_assistant.tools.default.prompt_templates import STANDARD_TOOLS_PROMPT\n",
    "from email_assistant.schemas import State, RouterSchema, StateInput\n",
    "from email_assistant.utils import parse_email, format_for_display, format_email_markdown\n",
    "\n",
    "# Agent tools \n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: datetime, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    date_str = preferred_day.strftime(\"%A, %B %d, %Y\")\n",
    "    return f\"Meeting '{subject}' scheduled on {date_str} at {start_time} for {duration_minutes} minutes with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
    "\n",
    "@tool\n",
    "class Question(BaseModel):\n",
    "      \"\"\"Question to ask user.\"\"\"\n",
    "      content: str\n",
    "    \n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"E-mail has been sent.\"\"\"\n",
    "      done: bool\n",
    "\n",
    "# All tools available to the agent\n",
    "tools = [\n",
    "    write_email, \n",
    "    schedule_meeting, \n",
    "    check_calendar_availability, \n",
    "    Question, \n",
    "    Done,\n",
    "]\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM for use with router / structured output\n",
    "llm = init_chat_model(\"openai:gpt-4o\", temperature=0.0)\n",
    "llm_router = llm.with_structured_output(RouterSchema) \n",
    "\n",
    "# Initialize the LLM, enforcing tool use (of any available tools) for agent\n",
    "llm = init_chat_model(\"openai:gpt-4o\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c508a7",
   "metadata": {},
   "source": [
    "### Nodes of the Email Assistant\n",
    "\n",
    "Our email assistant has several key nodes that handle different aspects of the workflow:\n",
    "\n",
    "1. **triage_router**: This node is responsible for analyzing incoming emails and classifying them into three categories:\n",
    "   - **RESPOND**: Emails that require a response from the assistant.\n",
    "   - **NOTIFY**: Important emails that don't need a response but should be brought to the user's attention.\n",
    "   - **IGNORE**: Low-priority emails that can be safely ignored.\n",
    "   \n",
    "   The router uses a structured output LLM to make this classification and then routes to the appropriate next node based on its decision.\n",
    "\n",
    "2. **triage_interrupt_handler**: When an email is classified as \"notify,\" this handler creates an interrupt to display the email in Agent Inbox and collect human feedback. This allows users to:\n",
    "   - Confirm the notification classification\n",
    "   - Provide feedback on how they would prefer similar emails to be classified in the future\n",
    "   \n",
    "   This feedback loop is crucial for improving the assistant's classification over time.\n",
    "\n",
    "3. **llm_call**: This node invokes the LLM with the available tools to decide how to respond to an email. The LLM might decide to:\n",
    "   - Draft a response email\n",
    "   - Schedule a meeting\n",
    "   - Ask the user a question\n",
    "   - Or mark the email as done\n",
    "\n",
    "Each of these nodes plays a specific role in the overall email processing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f44ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes \n",
    "def triage_router(state: State) -> Command[Literal[\"triage_interrupt_handler\", \"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\n",
    "\n",
    "    The triage step prevents the assistant from wasting time on:\n",
    "    - Marketing emails and spam\n",
    "    - Company-wide announcements\n",
    "    - Messages meant for other teams\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, to=to, subject=subject, email_thread=email_thread\n",
    "    )\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification  \n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Format system prompt with background and triage instructions\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=default_triage_instructions\n",
    "    )\n",
    "\n",
    "    # Run the router LLM\n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Decision\n",
    "    classification = result.classification\n",
    "\n",
    "    # Process the classification decision\n",
    "    if classification == \"respond\":\n",
    "        print(\"ðŸ“§ Classification: RESPOND - This email requires a response\")\n",
    "        # Next node\n",
    "        goto = \"response_agent\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": result.classification,\n",
    "            \"messages\": [{\"role\": \"user\",\n",
    "                            \"content\": f\"Respond to the email: {email_markdown}\"\n",
    "                        }],\n",
    "        }\n",
    "    elif classification == \"ignore\":\n",
    "        print(\"ðŸš« Classification: IGNORE - This email can be safely ignored\")\n",
    "\n",
    "        # Next node\n",
    "        goto = END\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    elif classification == \"notify\":\n",
    "        print(\"ðŸ”” Classification: NOTIFY - This email contains important information\") \n",
    "\n",
    "        # Next node\n",
    "        goto = \"triage_interrupt_handler\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {classification}\")\n",
    "    return Command(goto=goto, update=update)\n",
    "\n",
    "def triage_interrupt_handler(state: State) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Handles interrupts from the triage step\"\"\"\n",
    "    \n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification  \n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Create messages\n",
    "    messages = [{\"role\": \"user\",\n",
    "                \"content\": f\"Email to notify user about: {email_markdown}\"\n",
    "                }]\n",
    "\n",
    "    # Create interrupt for Agent Inbox\n",
    "    request = {\n",
    "        \"action_request\": {\n",
    "            \"action\": f\"Email Assistant: {state['classification_decision']}\",\n",
    "            \"args\": {}\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"allow_ignore\": True,  \n",
    "            \"allow_respond\": True, \n",
    "            \"allow_edit\": False, \n",
    "            \"allow_accept\": False,  \n",
    "        },\n",
    "        # Email to show in Agent Inbox\n",
    "        \"description\": email_markdown,\n",
    "    }\n",
    "\n",
    "    # Agent Inbox responds with a list  \n",
    "    response = interrupt([request])[0]\n",
    "\n",
    "    # If user provides feedback, go to response agent and use feedback to respond to email   \n",
    "    if response[\"type\"] == \"response\":\n",
    "        # Add feedback to messages \n",
    "        user_input = response[\"args\"]\n",
    "        # Used by the response agent\n",
    "        messages.append({\"role\": \"user\",\n",
    "                        \"content\": f\"User wants to reply to the email. Use this feedback to respond: {user_input}\"\n",
    "                        })\n",
    "        # Go to response agent\n",
    "        goto = \"response_agent\"\n",
    "\n",
    "    # If user ignores email, go to END\n",
    "    elif response[\"type\"] == \"ignore\":\n",
    "        goto = END\n",
    "\n",
    "    # Catch all other responses\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid response: {response}\")\n",
    "\n",
    "    # Update the state \n",
    "    update = {\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)\n",
    "\n",
    "def llm_call(state: State):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt_hitl.format(tools_prompt=STANDARD_TOOLS_PROMPT, \n",
    "                                                                                  background=default_background,\n",
    "                                                                                  response_preferences=default_response_preferences, \n",
    "                                                                                  cal_preferences=default_cal_preferences)}\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb9f50",
   "metadata": {},
   "source": [
    "### The interrupt_handler\n",
    "\n",
    "The `interrupt_handler` is the core HITL component of our response agent. Its job is to examine the tool calls that the LLM wants to make and determine which ones need human review before execution. Here's how it works:\n",
    "\n",
    "1. **Tool Selection**: The handler maintains a list of \"HITL tools\" that require human approval:\n",
    "   - `write_email`: Since sending emails has significant external impact\n",
    "   - `schedule_meeting`: Since scheduling meetings affects calendars\n",
    "   - `Question`: Since asking users questions requires direct interaction\n",
    "\n",
    "2. **Direct Execution**: Tools not in the HITL list (like `check_calendar_availability`) are executed immediately without interruption. This allows low-risk operations to proceed automatically.\n",
    "\n",
    "3. **Context Preparation**: For tools requiring review, the handler:\n",
    "   - Retrieves the original email for context\n",
    "   - Formats the tool call details for clear display\n",
    "   - Configures which interaction types are allowed for each tool type\n",
    "\n",
    "4. **Interrupt Creation**: The handler creates a structured interrupt request with:\n",
    "   - The action name and arguments\n",
    "   - Configuration for allowed interaction types\n",
    "   - A description that includes both the original email and the proposed action\n",
    "\n",
    "5. **Response Processing**: After the interrupt, the handler processes the human response:\n",
    "   - **Accept**: Executes the tool with original arguments\n",
    "   - **Edit**: Updates the tool call with edited arguments and then executes\n",
    "   - **Ignore**: Cancels the tool execution\n",
    "   - **Response**: Records feedback without execution\n",
    "\n",
    "This handler ensures humans have oversight of all significant actions while allowing routine operations to proceed automatically. The ability to edit tool arguments (like email content or meeting details) gives users precise control over the assistant's actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de9a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrupt_handler(state: State) -> Command[Literal[\"llm_call\", \"__end__\"]]:\n",
    "    \"\"\"Creates an interrupt for human review of tool calls\"\"\"\n",
    "    \n",
    "    # Store messages\n",
    "    result = []\n",
    "\n",
    "    # Go to the LLM call node next\n",
    "    goto = \"llm_call\"\n",
    "\n",
    "    # Iterate over the tool calls in the last message\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        \n",
    "        # Allowed tools for HITL\n",
    "        hitl_tools = [\"write_email\", \"schedule_meeting\", \"Question\"]\n",
    "        \n",
    "        # If tool is not in our HITL list, execute it directly without interruption\n",
    "        if tool_call[\"name\"] not in hitl_tools:\n",
    "\n",
    "            # Execute search_memory and other tools without interruption\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "            continue\n",
    "            \n",
    "        # Get original email from email_input in state\n",
    "        email_input = state[\"email_input\"]\n",
    "        author, to, subject, email_thread = parse_email(email_input)\n",
    "        original_email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "        \n",
    "        # Format tool call for display and prepend the original email\n",
    "        tool_display = format_for_display(state, tool_call)\n",
    "        description = original_email_markdown + tool_display\n",
    "\n",
    "        # Configure what actions are allowed in Agent Inbox\n",
    "        if tool_call[\"name\"] == \"write_email\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"Question\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": False,\n",
    "                \"allow_accept\": False,\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        # Create the interrupt request\n",
    "        request = {\n",
    "            \"action_request\": {\n",
    "                \"action\": tool_call[\"name\"],\n",
    "                \"args\": tool_call[\"args\"]\n",
    "            },\n",
    "            \"config\": config,\n",
    "            \"description\": description,\n",
    "        }\n",
    "\n",
    "        # Send to Agent Inbox and wait for response\n",
    "        response = interrupt([request])[0]\n",
    "\n",
    "        # Handle the responses \n",
    "        if response[\"type\"] == \"accept\":\n",
    "\n",
    "            # Execute the tool with original args\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "                        \n",
    "        elif response[\"type\"] == \"edit\":\n",
    "\n",
    "            # Tool selection \n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            \n",
    "            # Get edited args from Agent Inbox\n",
    "            edited_args = response[\"args\"][\"args\"]\n",
    "\n",
    "            # Update the write_email tool call with the edited content from Agent Inbox\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                \n",
    "                # Update the AI message's tool call with edited content (reference to the message in the state)\n",
    "                ai_message = state[\"messages\"][-1]\n",
    "                current_id = tool_call[\"id\"]\n",
    "                \n",
    "                # Replace the original tool call with the edited one (any changes made to this reference affect the original object in the state)\n",
    "                ai_message.tool_calls = [tc for tc in ai_message.tool_calls if tc[\"id\"] != current_id] + [\n",
    "                    {\"type\": \"tool_call\", \"name\": tool_call[\"name\"], \"args\": edited_args, \"id\": current_id}\n",
    "                ]\n",
    "                \n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "                \n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "            \n",
    "            # Update the schedule_meeting tool call with the edited content from Agent Inbox\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                \n",
    "                # Update the AI message's tool call with edited content\n",
    "                ai_message = state[\"messages\"][-1]\n",
    "                current_id = tool_call[\"id\"]\n",
    "                \n",
    "                # Replace the original tool call with the edited one\n",
    "                ai_message.tool_calls = [tc for tc in ai_message.tool_calls if tc[\"id\"] != current_id] + [\n",
    "                    {\"type\": \"tool_call\", \"name\": tool_call[\"name\"], \"args\": edited_args, \"id\": current_id}\n",
    "                ]\n",
    "                \n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "                \n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "            \n",
    "            # Catch all other tool calls\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        elif response[\"type\"] == \"ignore\":\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this email draft. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this calendar meeting draft. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this question. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "            \n",
    "        elif response[\"type\"] == \"response\":\n",
    "            # User provided feedback\n",
    "            user_feedback = response[\"args\"]\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the email. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the meeting request. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User answered the question, which can we can use for any follow up actions. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        # Catch all other responses\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid response: {response}\")\n",
    "            \n",
    "    # Update the state \n",
    "    update = {\n",
    "        \"messages\": result,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed953ed",
   "metadata": {},
   "source": [
    "### HITL Email Assistant Workflow\n",
    "\n",
    "Now we can integrate everything into a complete workflow that connects all the components. The workflow consists of two main parts:\n",
    "\n",
    "1. **Response Agent Subgraph**:\n",
    "   First, we build a standalone agent that can handle email responses:\n",
    "   - The `llm_call` node generates responses or tool calls\n",
    "   - The `should_continue` function checks if the agent is done or needs to use a tool\n",
    "   - The `interrupt_handler` manages human review of tool execution\n",
    "   - The cycle continues until the agent reaches a conclusion\n",
    "   \n",
    "   This response agent is compiled as a reusable subgraph.\n",
    "\n",
    "2. **Overall Email Assistant Workflow**:\n",
    "   Then, we create the main workflow that:\n",
    "   - Starts with `triage_router` to classify the email\n",
    "   - Routes to `triage_interrupt_handler` for NOTIFY classifications\n",
    "   - Routes to `response_agent` for RESPOND classifications\n",
    "   - Ends immediately for IGNORE classifications\n",
    "\n",
    "This architecture provides a clean separation of concerns, with distinct components for triage, response generation, and human oversight. The resulting workflow gives us a complete email assistant that:\n",
    "\n",
    "- Analyzes incoming emails\n",
    "- Correctly routes them based on importance\n",
    "- Engages humans for oversight at critical decision points\n",
    "- Responds appropriately to important emails\n",
    "\n",
    "The final graph visualization shows the complete flow from email input through triage and, when necessary, through the response generation process with human oversight at each significant step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db309a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge function\n",
    "def should_continue(state: State) -> Literal[\"interrupt_handler\", END]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls: \n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"interrupt_handler\"\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"interrupt_handler\", interrupt_handler)\n",
    "\n",
    "# Add edges\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"interrupt_handler\": \"interrupt_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile the agent\n",
    "response_agent = agent_builder.compile()\n",
    "\n",
    "# Build overall workflow\n",
    "overall_workflow = (\n",
    "    StateGraph(State, input=StateInput)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(triage_interrupt_handler)\n",
    "    .add_node(\"response_agent\", response_agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    "    \n",
    ")\n",
    "\n",
    "email_assistant = overall_workflow.compile()\n",
    "display(Image(email_assistant.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bac65b",
   "metadata": {},
   "source": [
    "Now, we can test the workflow! \n",
    "\n",
    "## Accept `write_email` and `schedule_meeting`\n",
    "\n",
    "This test demonstrates the fundamental HITL approval flow when a user accepts all agent actions:\n",
    "1. An email about tax planning is received and classified as \"RESPOND\"\n",
    "2. The agent checks calendar availability for both suggested dates (Tuesday and Thursday)\n",
    "3. The agent proposes scheduling a meeting on Tuesday at 2:00 PM for 45 minutes\n",
    "4. The user reviews and ACCEPTS the meeting request without changes\n",
    "5. The agent drafts a confirmation email to send to the client\n",
    "6. The user reviews and ACCEPTS the email draft without changes\n",
    "7. The agent marks the workflow as complete\n",
    "\n",
    "This scenario shows how human-in-the-loop works at its most basic level - humans provide oversight while the agent handles the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_1 = uuid.uuid4()\n",
    "thread_config_1 = {\"configurable\": {\"thread_id\": thread_id_1}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454d987",
   "metadata": {},
   "source": [
    "Accept the `schedule_meeting` tool call\n",
    "\n",
    "After the agent proposes scheduling a meeting, it creates an interrupt to seek human approval. In this step, we simulate a user accepting the proposed meeting parameters without changes. This allows the workflow to proceed to the next step (drafting a confirmation email). The interrupt object contains critical information:\n",
    "\n",
    "1. The action type (`schedule_meeting`)\n",
    "2. The proposed meeting parameters (attendees, subject, duration, day, time)\n",
    "3. Configuration options for what kinds of responses are allowed\n",
    "\n",
    "When the user accepts, the tool is executed as proposed without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d8c1a5",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call\n",
    "\n",
    "With the meeting scheduled, the agent now drafts a confirmation email to the client. The interrupt contains:\n",
    "\n",
    "1. The email tool action with recipient, subject, and proposed content\n",
    "2. The formatted email showing what will be sent\n",
    "3. The same configuration options for user response types\n",
    "\n",
    "When the user accepts, the email is sent as written. After this step, the agent marks the task as complete with the `Done` tool call, and the workflow ends. The complete message history shows all the steps taken:\n",
    "\n",
    "1. Initial email processing\n",
    "2. Calendar availability checks for both days\n",
    "3. Meeting scheduling with confirmation\n",
    "4. Email composition and sending\n",
    "5. Workflow completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d228ff8",
   "metadata": {},
   "source": [
    "Look at the full message history, and see trace:\n",
    "\n",
    "https://smith.langchain.com/public/82277f96-3abd-48e0-a4db-413f7572240d/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b168d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_1)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1ba30",
   "metadata": {},
   "source": [
    "## Edit `write_email` and `schedule_meeting`\n",
    "\n",
    "This test demonstrates how human modification works in the HITL flow:\n",
    "1. We start with the same tax planning email as before\n",
    "2. The agent proposes a meeting with the same parameters\n",
    "3. This time, the user EDITS the meeting proposal to change:\n",
    "   - Duration from 45 to 30 minutes\n",
    "   - Meeting subject is made more concise\n",
    "4. The agent adapts to these changes when drafting the email\n",
    "5. The user further EDITS the email to be shorter and less formal\n",
    "6. The workflow completes with both modifications incorporated\n",
    "\n",
    "This scenario showcases one of the most powerful aspects of HITL: users can make precise modifications to agent actions before they are executed, ensuring the final outcome matches their preferences without having to handle all the details themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfca1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same email as before\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_2 = uuid.uuid4()\n",
    "thread_config_2 = {\"configurable\": {\"thread_id\": thread_id_2}}\n",
    "\n",
    "# Run the graph until the first interrupt - will be classified as \"respond\" and the agent will create a write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_2):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ac0a6",
   "metadata": {},
   "source": [
    "Edit the `schedule_meeting` tool call\n",
    "\n",
    "When the agent proposes the initial meeting schedule, we now simulate the user making modifications through the edit functionality. This demonstrates how the `edit` response type works:\n",
    "\n",
    "1. The user receives the same meeting proposal as in the previous test\n",
    "2. Instead of accepting, they modify the parameters:\n",
    "   - Reducing duration from 45 to 30 minutes\n",
    "   - Keeping the same day and time\n",
    "3. The `edit` response includes the complete set of modified arguments\n",
    "4. The interrupt handler replaces the original tool arguments with these edited ones\n",
    "5. The tool is executed with the user's modifications\n",
    "\n",
    "This shows how edit capability gives users precise control over agent actions while still letting the agent handle the execution details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simulate user editing the schedule_meeting tool call\n",
    "print(\"\\nSimulating user editing the schedule_meeting tool call...\")\n",
    "edited_schedule_args = {\n",
    "    \"attendees\": [\"pm@client.com\", \"lance@company.com\"],\n",
    "    \"subject\": \"Tax Planning Discussion\",\n",
    "    \"duration_minutes\": 30,  # Changed from 45 to 30\n",
    "    \"preferred_day\": \"2025-04-22\",\n",
    "    \"start_time\": 14 \n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_schedule_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757706b",
   "metadata": {},
   "source": [
    "Edit the `write_email` tool call\n",
    "\n",
    "After accepting the modified meeting schedule, the agent drafts an email reflecting the 30-minute duration. Now we demonstrate how editing works with email content:\n",
    "\n",
    "1. The agent has adapted its email to mention the shorter 30-minute duration\n",
    "2. We simulate the user wanting an even more significant change to the email:\n",
    "   - Completely rewriting the content to be shorter and less formal\n",
    "   - Changing the meeting day mentioned in the email (showing how users can correct agent mistakes)\n",
    "   - Requesting confirmation rather than stating the meeting as definite\n",
    "3. The `edit` response contains the complete new email content\n",
    "4. The tool arguments are updated with this edited content\n",
    "5. The email is sent with the user's preferred wording\n",
    "\n",
    "This example shows the power of HITL for complex communication tasks - the agent handles the structure and initial content, while humans can refine tone, style, and substance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0604d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simulate user editing the write_email tool call\n",
    "print(\"\\nSimulating user editing the write_email tool call...\")\n",
    "edited_email_args = {\n",
    "    \"to\": \"pm@client.com\",\n",
    "    \"subject\": \"Re: Tax season let's schedule call\",\n",
    "    \"content\": \"Hello Project Manager,\\n\\nThank you for reaching out about tax planning. I scheduled a 30-minute call next Thursday at 3:00 PM. Would that work for you?\\n\\nBest regards,\\nLance Martin\"\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_email_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac279101",
   "metadata": {},
   "source": [
    "Look at the full message history, and see trace, to view the edited tool calls:\n",
    "\n",
    "https://smith.langchain.com/public/21769510-d57a-41e4-b5c7-0ddb23c237d8/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_2)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281cb1f",
   "metadata": {},
   "source": [
    "## Ignore `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "This test set demonstrates the \"ignore\" capability of the HITL system, showing how users can reject agent actions entirely:\n",
    "\n",
    "1. First, we test ignoring a `schedule_meeting` request:\n",
    "   - When the agent proposes scheduling a meeting, the user rejects it completely\n",
    "   - The workflow ends immediately without scheduling anything\n",
    "   \n",
    "2. Second, we test accepting a meeting but ignoring the follow-up email:\n",
    "   - The user accepts the meeting schedule\n",
    "   - But when the agent drafts a confirmation email, the user ignores it\n",
    "   - The meeting is still scheduled, but no email is sent\n",
    "   - The workflow ends after the rejection\n",
    "\n",
    "3. Third, we test ignoring a `question` tool call:\n",
    "   - For a different email about brunch plans\n",
    "   - The agent asks a clarifying question\n",
    "   - The user ignores the question\n",
    "   - The workflow ends without further action\n",
    "\n",
    "The \"ignore\" capability is crucial for HITL systems as it allows users to stop potentially unwanted actions before they occur, providing an important safety mechanism and ensuring users maintain full control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60baeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_3 = uuid.uuid4()\n",
    "thread_config_3 = {\"configurable\": {\"thread_id\": thread_id_3}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_3):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442cc81",
   "metadata": {},
   "source": [
    "Ignore the `schedule_meeting` tool call\n",
    "\n",
    "In this test, we demonstrate rejection of the meeting scheduling proposal:\n",
    "\n",
    "1. The agent suggests a 45-minute meeting on Tuesday at 2:00 PM\n",
    "2. We simulate the user selecting \"ignore\" in the Agent Inbox interface\n",
    "3. The `interrupt_handler` processes this rejection with special logic:\n",
    "   - It adds a message explaining the user's choice to ignore\n",
    "   - It returns a command to end the workflow\n",
    "   - No meeting is scheduled and no email is sent\n",
    "\n",
    "This capability is crucial for several reasons:\n",
    "- Prevents incorrect actions from being executed\n",
    "- Gives users veto power over any agent decision\n",
    "- Provides a clear exit path when the agent's suggestion isn't appropriate\n",
    "\n",
    "The trace shows how the workflow ends immediately after the ignore action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e86ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_3):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ccb8e0",
   "metadata": {},
   "source": [
    "As you can see from the trace, we end:\n",
    "\n",
    "https://smith.langchain.com/public/4e322b99-08ea-4d23-9653-475415ff3e33/r\n",
    "\n",
    "Now, let's run again, but ignore the `write_email` tool call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e33156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_3 = uuid.uuid4()\n",
    "thread_config_3 = {\"configurable\": {\"thread_id\": thread_id_3}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_3):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_3):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_3):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acea519",
   "metadata": {},
   "source": [
    "Again, we end:\n",
    "\n",
    "https://smith.langchain.com/public/819be555-4919-4d14-bdd9-eb6f73a3bafe/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_3)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7200cdaf",
   "metadata": {},
   "source": [
    "Now let's try an email that calls the `Question` tool\n",
    "\n",
    "The `Question` tool represents another important HITL interaction pattern - the agent asking for additional information rather than taking immediate action. This test shows:\n",
    "\n",
    "1. A different email scenario about a potential brunch invitation\n",
    "2. The agent doesn't have enough information to respond definitively\n",
    "3. Instead of guessing, it uses the `Question` tool to ask for clarification\n",
    "4. We'll simulate the user ignoring this question\n",
    "\n",
    "This demonstrates how the HITL system gracefully handles requests for information, and what happens when users choose not to engage with these requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Partner <partner@home.com>\",\n",
    "    \"subject\": \"Meet Jim and Lisa for brunch in 3 weeks?\",\n",
    "    \"email_thread\": \"Hey, should we invite Jim and Lisa to brunch in 3 weeks? We could go to the new place on 17th that everyone is talking about.\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_4 = uuid.uuid4()\n",
    "thread_config_4 = {\"configurable\": {\"thread_id\": thread_id_4}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_4):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaca6d4",
   "metadata": {},
   "source": [
    "Ignore the `question` tool call\n",
    "\n",
    "When the agent asks for clarification about the brunch plans, we simulate a user ignoring the question:\n",
    "\n",
    "1. The agent has asked about preferred day and time for the brunch\n",
    "2. We provide an \"ignore\" response to this question\n",
    "3. The system processes this as a decision to abandon handling this email:\n",
    "   - A message is added stating \"User ignored this question. Ignore this email and end the workflow.\"\n",
    "   - The workflow ends without sending any response\n",
    "\n",
    "This pattern is important because it allows users to:\n",
    "- Decide that some emails don't actually need responses\n",
    "- Avoid providing information they're not ready to share\n",
    "- Defer decision-making to a later time\n",
    "- Take over email handling manually if they prefer\n",
    "\n",
    "The trace and message history show how cleanly the workflow ends after ignoring the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_4):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7ade4",
   "metadata": {},
   "source": [
    "As before, we end:\n",
    "\n",
    "https://smith.langchain.com/public/276c4016-2b4c-43f5-a677-834a5eaa47c0/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef334860",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_4)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c39e9",
   "metadata": {},
   "source": [
    "## Respond (with feedback) `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "This test set demonstrates the \"response\" capability - providing feedback without editing or accepting:\n",
    "\n",
    "1. First, we test feedback for meeting scheduling:\n",
    "   - The user provides specific preferences (30 minutes instead of 45, and afternoon meetings)\n",
    "   - The agent incorporates this feedback into a revised proposal\n",
    "   - The user then accepts the revised meeting schedule\n",
    "\n",
    "2. Second, we test feedback for email drafting:\n",
    "   - The user requests a shorter, less formal email with a specific closing statement\n",
    "   - The agent completely rewrites the email according to this guidance\n",
    "   - The user accepts the new draft\n",
    "\n",
    "3. Lastly, we test feedback for questions:\n",
    "   - For the brunch invitation, the user answers the question with additional context\n",
    "   - The agent uses this information to draft an appropriate email response\n",
    "   - The workflow proceeds with the user's input integrated\n",
    "\n",
    "The \"response\" capability bridges the gap between acceptance and editing - users can guide the agent without having to write the full content themselves. This is especially powerful for:\n",
    "- Adjusting tone and style\n",
    "- Adding context the agent missed\n",
    "- Redirecting the agent's approach\n",
    "- Answering questions in a way that shapes the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b3517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_5 = uuid.uuid4()\n",
    "thread_config_5 = {\"configurable\": {\"thread_id\": thread_id_5}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2bea0a",
   "metadata": {},
   "source": [
    "Provide feedback for the `schedule_meeting` tool call\n",
    "\n",
    "Now we explore the feedback capability for meeting scheduling:\n",
    "\n",
    "1. The agent proposes the standard 45-minute meeting on Tuesday at 2:00 PM\n",
    "2. Instead of accepting or editing, we provide feedback in natural language\n",
    "3. Our feedback specifies two preferences:\n",
    "   - Shorter meeting (30 minutes instead of 45)\n",
    "   - Preference for afternoon meetings (after 2pm)\n",
    "4. The agent receives this feedback through the `response` type\n",
    "5. The interrupt handler adds this feedback as a message to the state\n",
    "6. The agent processes this feedback and generates a new tool call incorporating these preferences\n",
    "\n",
    "Unlike direct editing, which requires specifying the entire set of parameters, feedback allows users to express their preferences conversationally. The agent must then interpret this feedback and apply it appropriately to create a revised proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a916e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35f1a2",
   "metadata": {},
   "source": [
    "Accept the `schedule_meeting` tool call after providing feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca470c5",
   "metadata": {},
   "source": [
    "Now provide feedback for the `write_email` tool call\n",
    "\n",
    "After accepting the revised meeting schedule, the agent drafts an email. We now test feedback for email content:\n",
    "\n",
    "1. The agent's email is relatively formal and detailed\n",
    "2. We provide stylistic feedback requesting:\n",
    "   - A shorter, more concise email\n",
    "   - A less formal tone\n",
    "   - A specific closing statement about looking forward to the meeting\n",
    "3. The agent processes this feedback to completely rewrite the email\n",
    "4. The new draft is much shorter, more casual, and includes the requested closing\n",
    "\n",
    "This demonstrates the power of natural language feedback for content creation:\n",
    "- Users don't need to rewrite the entire email themselves\n",
    "- They can provide high-level guidance on style, tone, and content\n",
    "- The agent handles the actual writing based on this guidance\n",
    "- The result better matches user preferences while preserving the essential information\n",
    "\n",
    "The message history shows both the original and revised emails, clearly showing how the feedback was incorporated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5221d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Shorter and less formal. Include a closing statement about looking forward to the meeting!\"}]), config=thread_config_5):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266ec72",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call after providing feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270f52a",
   "metadata": {},
   "source": [
    "Look at the full message history, and see the trace:\n",
    "\n",
    "https://smith.langchain.com/public/57006770-6bb3-4e40-b990-143c373ebe60/r\n",
    "\n",
    "We can see that user feedback in incorporated into the tool calls.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_5)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d964e36",
   "metadata": {},
   "source": [
    "Now let's try an email that calls the `Question` tool to provide feedback\n",
    "\n",
    "Finally, we test how feedback works with the `Question` tool:\n",
    "\n",
    "1. For the brunch invitation email, the agent asks about preferred day and time\n",
    "2. Instead of ignoring, we provide a substantive response with additional context:\n",
    "   - Confirming we want to invite the people mentioned\n",
    "   - Noting we need to check which weekend works best\n",
    "   - Adding information about needing a reservation\n",
    "3. The agent uses this information to:\n",
    "   - Draft a comprehensive email response incorporating all our feedback\n",
    "   - Notice we didn't provide a specific day/time, so it suggests checking the calendar\n",
    "   - Include the detail about making a reservation\n",
    "4. The complete email reflects both the original request and our additional guidance\n",
    "\n",
    "This demonstrates how question responses can shape the entire workflow:\n",
    "- Questions let the agent gather missing information\n",
    "- User responses can include both direct answers and additional context\n",
    "- The agent integrates all this information into its next actions\n",
    "- The final outcome reflects the collaborative intelligence of both human and AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Partner <partner@home.com>\",\n",
    "    \"subject\": \"Meet Jim and Lisa for brunch in 3 weeks?\",\n",
    "    \"email_thread\": \"Hey, should we invite Jim and Lisa to brunch in 3 weeks? We could go to the new place on 17th that everyone is talking about.\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_6 = uuid.uuid4()\n",
    "thread_config_6 = {\"configurable\": {\"thread_id\": thread_id_6}}\n",
    "\n",
    "# Run the graph until the first interrupt\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_6):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f7f1b",
   "metadata": {},
   "source": [
    "Provide feedback for the `Question` tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Yes, let's invite them, but let me confirm which weekend works best. Also mention that we'll need to make a reservation since that place is popular.\"}]), config=thread_config_6):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4ba9b",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd34ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_6):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214fe9e",
   "metadata": {},
   "source": [
    "Look at the full message history, and see the trace:\n",
    "\n",
    "https://smith.langchain.com/public/f4c727c3-b1d9-47a5-b3d0-3451619db8a2/r\n",
    "\n",
    "We can see that user feedback in incorporated into the email response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070393eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_6)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8036348c",
   "metadata": {},
   "source": [
    "## Test Case for Notify Classification\n",
    "\n",
    "This test demonstrates how the system handles emails classified as \"NOTIFY\" and how users can respond to notifications:\n",
    "\n",
    "1. The triage system classifies important informational emails as \"NOTIFY\" when:\n",
    "   - They contain important information (like security updates)\n",
    "   - They don't require immediate action\n",
    "   - They should be brought to the user's attention\n",
    "   \n",
    "2. For notify classifications:\n",
    "   - The workflow routes to the `triage_interrupt_handler`\n",
    "   - The user sees the email content with options to ignore or respond\n",
    "   - No default action is suggested\n",
    "\n",
    "3. In this test, we:\n",
    "   - Process an IT security update email that gets classified as \"NOTIFY\"\n",
    "   - Simulate the user deciding to respond with specific feedback\n",
    "   - See how the agent drafts an appropriate response based on this feedback\n",
    "   - Approve the response to be sent\n",
    "\n",
    "This showcases how the HITL system can transform a passive notification into an active response when the user decides one is warranted, bridging the gap between the initial \"NOTIFY\" classification and a full response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notify - Important FYI Email\n",
    "email_input_notify = {\n",
    "    \"to\": \"Team Members <team@company.com>\",\n",
    "    \"author\": \"IT Department <it@company.com>\",\n",
    "    \"subject\": \"Critical Security Update\",\n",
    "    \"email_thread\": \"Dear Team,\\n\\nThis is an important security notification. We will be updating our authentication system this weekend. During the update window (Saturday 2am-4am), you will not be able to access company resources.\\n\\nPlease ensure you log out of all systems before the maintenance window.\\n\\nRegards,\\nIT Department\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_7 = uuid.uuid4()\n",
    "thread_config_7 = {\"configurable\": {\"thread_id\": thread_id_7}}\n",
    "\n",
    "# Run the graph until the first interrupt - should be classified as \"notify\"\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_notify}, config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d062bb",
   "metadata": {},
   "source": [
    "Now simulate user deciding to respond with feedback.\n",
    "\n",
    "Although the email was classified as \"NOTIFY\" (meaning it normally wouldn't require a response), the HITL system gives users the flexibility to override this classification. In this step:\n",
    "\n",
    "1. We provide feedback indicating we want to acknowledge receipt of the security notice\n",
    "2. The `triage_interrupt_handler` processes this feedback:\n",
    "   - It adds the user's guidance as a message to the state\n",
    "   - It routes to the `response_agent` node instead of ending\n",
    "3. The response agent uses this guidance to draft an appropriate acknowledgment email\n",
    "4. An interrupt is created for the user to review this draft before sending\n",
    "\n",
    "This demonstrates an important capability: the ability for users to override the initial classification when they feel a response is warranted. This ensures that the system remains flexible and adaptable to user preferences, while still providing useful initial triage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd027a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating user deciding to respond with feedback...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"We should acknowledge receipt of this important notice and confirm that we'll be logged out before the maintenance window.\"}]), config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84de751",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call after feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073642cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270fa6c",
   "metadata": {},
   "source": [
    "Look at the full message history, and see the trace:\n",
    "\n",
    "https://smith.langchain.com/public/6594f98f-eb83-4560-9c34-28ec22ada3dc/r\n",
    "\n",
    "We can see that user feedback causes agent to go reply to the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bbc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_7)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318fce72",
   "metadata": {},
   "source": [
    "## Test Case for Notify + Ignore\n",
    "\n",
    "This test demonstrates the other path for notifications - when users choose to simply acknowledge without responding:\n",
    "\n",
    "1. We process a company picnic announcement email, which gets classified as \"NOTIFY\"\n",
    "2. The user decides this notification needs no response and chooses to ignore it\n",
    "3. The workflow ends immediately with no further action\n",
    "\n",
    "This scenario highlights several key aspects of the HITL system:\n",
    "- The initial triage correctly identifies information that's worth seeing but doesn't require action\n",
    "- Users can quickly process such notifications with minimal interaction\n",
    "- The system respects the user's decision not to act\n",
    "- The workflow efficiently ends without wasting time on unnecessary steps\n",
    "\n",
    "Together with the previous test, this demonstrates the complete notification handling workflow:\n",
    "- Some notifications warrant responses (previous test)\n",
    "- Others simply need acknowledgment (this test)\n",
    "- The user maintains control over which path to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notify - Important FYI Email\n",
    "email_input_notify = {\n",
    "    \"to\": \"Team Members <team@company.com>\",\n",
    "    \"author\": \"HR Department <hr@company.com>\",\n",
    "    \"subject\": \"Company Picnic Next Month\",\n",
    "    \"email_thread\": \"Dear Team,\\n\\nWe're planning the annual company picnic for next month. The tentative date is Saturday, June 15th from noon to 4pm at Central Park. There will be food, games, and activities for families.\\n\\nMore details will follow in the coming weeks.\\n\\nRegards,\\nHR Department\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_8 = uuid.uuid4()\n",
    "thread_config_8 = {\"configurable\": {\"thread_id\": thread_id_8}}\n",
    "\n",
    "# Run the graph until the first interrupt - should be classified as \"notify\"\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_notify}, config=thread_config_8):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44290b",
   "metadata": {},
   "source": [
    "Now simulate user deciding to ignore the notification.\n",
    "\n",
    "In this step, we simulate the simplest path for notification handling - acknowledgment without action:\n",
    "\n",
    "1. We receive the interrupt with the notification about the company picnic\n",
    "2. We respond with the \"ignore\" response type\n",
    "3. The workflow immediately ends without creating any responses\n",
    "4. The message history shows only the notification itself, with no additional processing\n",
    "\n",
    "This straightforward path is actually critical for workflow efficiency:\n",
    "- It allows users to quickly process informational emails\n",
    "- It avoids the overhead of unnecessary response generation\n",
    "- It recognizes that many notifications simply need to be seen, not answered\n",
    "- It respects the user's time by ending the workflow immediately\n",
    "\n",
    "The complete message history shows how clean this path is - just the notification itself, with no additional messages once the user chooses to ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating user deciding to ignore the notification...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_8):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7269bb",
   "metadata": {},
   "source": [
    "Look at the full message history, and see the trace:\n",
    "\n",
    "https://smith.langchain.com/public/8193f616-244f-471d-8ec6-bd39624a0c88/r\n",
    "\n",
    "Here, we can see that if we ignore the notification, we just end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5dbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_8)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5a2b66",
   "metadata": {},
   "source": [
    "## Testing with Local Deployment\n",
    "\n",
    "The HITL email assistant can be tested in a real interactive environment using LangGraph Studio and Agent Inbox. This allows you to experience the full workflow with an actual user interface:\n",
    "\n",
    "1. **LangGraph Studio** provides:\n",
    "   - A visual interface for the graph execution\n",
    "   - Real-time visibility into state transitions\n",
    "   - Ability to see and respond to interrupts directly\n",
    "   - Debugging capabilities to understand the flow\n",
    "\n",
    "2. **Agent Inbox** provides:\n",
    "   - A purpose-built HITL interface for reviewing agent actions\n",
    "   - Visual display of email content in a readable format\n",
    "   - Action buttons for accept, edit, ignore, and respond\n",
    "   - Context-specific controls based on the action type\n",
    "\n",
    "You can test this locally by:\n",
    "1. Running the graph with `langgraph dev` (using the implementation in `src/email_assistant/email_assistant_hitl.py`)\n",
    "2. Connecting Agent Inbox to your local graph\n",
    "3. Submitting test emails through LangGraph Studio\n",
    "4. Reviewing and approving/editing actions in Agent Inbox\n",
    "\n",
    "This setup allows for end-to-end testing of the entire HITL workflow with a realistic user experience, bridging the gap between the programmatic tests in this notebook and real-world usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a57e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! langgraph dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68c776e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Example e-mail you can test:\n",
    "\n",
    "Below is a sample email for testing the HITL workflow in LangGraph Studio. This example represents a technical query that would be classified as \"RESPOND\" and would likely trigger tool use:\n",
    "\n",
    "1. The email asks about missing API documentation for authentication endpoints\n",
    "2. It's specific enough for the agent to draft a meaningful response\n",
    "3. It might prompt the agent to:\n",
    "   - Acknowledge the missing documentation\n",
    "   - Offer to update the docs\n",
    "   - Ask clarifying questions about what exactly is needed\n",
    "\n",
    "When using this example:\n",
    "- Copy and paste it into the LangGraph Studio input field\n",
    "- Follow the execution in real-time as it moves through triage and response generation\n",
    "- Observe how the system creates interrupts at decision points\n",
    "- Experiment with different response types (accept, edit, ignore, respond) to see how they affect the workflow\n",
    "\n",
    "This hands-on testing helps build intuition for how the HITL system behaves with real inputs and how different user decisions impact the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_input = {\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1be24",
   "metadata": {},
   "source": [
    "When you submit the e-mail, you will see the interrupt in Studio. This displays the full `request` object that was passed to the `interrupt` function.\n",
    "\n",
    "![studio-img](img/studio-interrupt.png)\n",
    " \n",
    "If you go to [dev.agentinbox.ai](https://dev.agentinbox.ai/), you can add the graph url:\n",
    "   * Graph name: the name from the `langgraph.json` file (`email_assistant_hitl`)\n",
    "   * Graph URL: `http://127.0.0.1:2024/`\n",
    "\n",
    "All interrupted threads run will be visible. Any e-mail triaged to `Notify` will be displayed in Agent Inbox with the action request in `triage_interrupt_handler`, allowing you to ignore or respond with feedback. In addition, any email marked with `Respond` will be displayed in Agent Inbox with the action request in `interrupt_handler`, allowing you to review tool calls from `[\"write_email\", \"schedule_meeting\", \"Question\"]`.\n",
    "\n",
    "![agent-inbox-img](img/agent-inbox.png)\n",
    "\n",
    "The Agent Inbox interface provides a rich, user-friendly environment for HITL interactions:\n",
    "\n",
    "1. **Email Content Display**: The original email is shown prominently at the top for context\n",
    "2. **Action Request**: Below the email, you see the proposed action (write_email, schedule_meeting, etc.)\n",
    "3. **Action Parameters**: For each action, the specific parameters are displayed in a structured format\n",
    "4. **Interaction Buttons**: Based on the configuration, you'll see buttons for available interactions:\n",
    "   - ACCEPT: Approve the action as-is\n",
    "   - EDIT: Modify the parameters before execution\n",
    "   - IGNORE: Reject the action entirely\n",
    "   - RESPOND: Provide feedback or answers without editing\n",
    "\n",
    "In the case of `write_email`, you can fully edit the email content in a rich text editor, allowing for precise control over the final message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"allow_ignore\": True,\n",
    "    \"allow_respond\": True,\n",
    "    \"allow_edit\": True,\n",
    "    \"allow_accept\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320be47",
   "metadata": {},
   "source": [
    "![agent-inbox-img](img/agent-inbox-draft.png)\n",
    "\n",
    "This screenshot shows the email editing interface in Agent Inbox:\n",
    "\n",
    "1. **Draft Email Display**: The complete email draft is presented in a readable format\n",
    "2. **Rich Text Editor**: When editing, you get a full-featured editor to modify the content\n",
    "3. **Original Email Context**: The original email remains visible for reference\n",
    "4. **Action Buttons**: Options to accept, ignore, edit, or provide feedback\n",
    "\n",
    "This real-world interface brings together all the concepts explored in this notebook:\n",
    "- The email assistant analyzes and triages incoming messages\n",
    "- It proposes appropriate actions based on email content\n",
    "- Humans review these proposals through a purpose-built interface\n",
    "- Different interaction types (accept, edit, ignore, respond) offer varying levels of control\n",
    "- The workflow adapts based on human feedback\n",
    "\n",
    "The combination of LangGraph's interrupt mechanism with Agent Inbox's interface creates a powerful HITL system that balances automation with human oversight - exactly what's needed for sensitive tasks like email management."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
