{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d047044f",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "We've used Human-in-the-Loop (HITL) to allow users to review, provide feedback on, or correct the assistant's decisions. This is great, but it would be even better if the assistant *could learn from* the user's edit / feedback and adapt to their preferences over time. This is where memory comes in. Memory is a critical and emerging component of agent systems, allowing them to learn and improve over time. In this section, we'll add memory to our email assistant, allowing it to learn from user feedback and adapt to their preferences over time. This gives us more confidence that the assistant acts on our behalf with personalization. \n",
    "\n",
    "![overview-img](img/overview_memory.png)\n",
    "\n",
    "## Memory in LangGraph\n",
    "\n",
    "### Thread-Scoped and Across-Thread Memory\n",
    "\n",
    "First, it's worth explaining how [memory works in LangGraph](https://langchain-ai.github.io/langgraph/concepts/memory/). LangGraph offers two distinct types of memory that serve complementary purposes in agent systems:\n",
    "\n",
    "**Thread-Scoped Memory (Short-term)** operates within the boundaries of a single conversation thread. It's automatically managed as part of the graph's state and persisted through thread-scoped checkpoints. This memory type retains conversation history, uploaded files, retrieved documents, and other artifacts generated during the interaction. Think of it as the working memory that maintains context within one specific conversation, allowing the agent to reference earlier messages or actions without starting from scratch each time.\n",
    "\n",
    "**Across-Thread Memory (Long-term)** extends beyond individual conversations, creating a persistent knowledge base that spans multiple sessions. This memory is stored as JSON documents in a memory store, organized by namespaces (like folders) and distinct keys (like filenames). Unlike thread-scoped memory, this information persists even after conversations end, enabling the system to recall user preferences, past decisions, and accumulated knowledge. This is what allows an agent to truly learn and adapt over time, rather than treating each interaction as isolated.\n",
    "\n",
    "![short-vs-long-term-memory](img/short-vs-long.png)\n",
    "\n",
    "The [Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) is the foundation of this architecture, providing a flexible database where memories can be organized, retrieved, and updated. What makes this approach powerful is that regardless of which memory type you're working with, the same Store interface provides consistent access patterns. This allows your agent's code to remain unchanged whether you're using a simple in-memory implementation during development or a production-grade database in deployment. \n",
    "\n",
    "### LangGraph Store\n",
    "\n",
    "LangGraph offers different [Store implementations depending on your deployment scenario](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore):\n",
    "\n",
    "1. **Pure In-Memory (e.g., notebooks)**:\n",
    "   - Uses `from langgraph.store.memory import InMemoryStore`\n",
    "   - Purely a Python dictionary in memory with no persistence\n",
    "   - Data is lost when the process terminates\n",
    "   - Useful for quick experiments and testing\n",
    "   - Includes semantic search with cosine similarity\n",
    "\n",
    "2. **Local Development with `langgraph dev`**:\n",
    "   - Similar to InMemoryStore but with pseudo-persistence\n",
    "   - Data is pickled to the local filesystem between restarts\n",
    "   - Lightweight and fast, no need for external databases\n",
    "   - Semantic search uses cosine similarity for embedding comparisons\n",
    "   - Great for development but not designed for production use\n",
    "\n",
    "3. **LangGraph Platform or Production Deployments**:\n",
    "   - Uses PostgreSQL with pgvector for production-grade persistence\n",
    "   - Fully persistent data storage with reliable backups\n",
    "   - Scalable for larger datasets\n",
    "   - High-performance semantic search via pgvector\n",
    "   - Default distance metric is cosine similarity (customizable)\n",
    "\n",
    "Let's use the `InMemoryStore` here in the notebook! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fa1dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb204c",
   "metadata": {},
   "source": [
    "Memories are namespaced by a tuple, which in this specific example will be (`<user_id>`, \"memories\"). The namespace can be any length and represent anything, does not have to be user specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0488a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8b303",
   "metadata": {},
   "source": [
    "We use the `store.put` method to save memories to our namespace in the store. When we do this, we specify the namespace, as defined above, and a key-value pair for the memory: the key is simply a unique identifier for the memory (memory_id) and the value (a dictionary) is the memory itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4af95b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "memory_id = str(uuid.uuid4())\n",
    "memory = {\"food_preference\" : \"I like pizza\"}\n",
    "in_memory_store.put(namespace_for_memory, memory_id, memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60408492",
   "metadata": {},
   "source": [
    "We can read out memories in our namespace using the `store.search` method, which will return all memories for a given user as a list. The most recent memory is the last in the list. Each memory type is a Python class (`Item`) with certain attributes. We can access it as a dictionary by converting via `.dict` as above. The attributes it has are shown below, but the most important ones is typically `value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c25f5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': 'd495e1d1-a21e-49bf-a4a1-cc46b42ff5fd',\n",
       " 'value': {'food_preference': 'I like pizza'},\n",
       " 'created_at': '2025-04-17T03:12:16.148584+00:00',\n",
       " 'updated_at': '2025-04-17T03:12:16.148587+00:00',\n",
       " 'score': None}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "memories[-1].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c982928",
   "metadata": {},
   "source": [
    "To use this in a graph, all we need to do is compile the graph with the store:\n",
    "\n",
    "```\n",
    "# We need this because we want to enable threads (conversations)\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "checkpointer = InMemorySaver()\n",
    "# We need this because we want to enable across-thread memory\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()\n",
    "# Compile the graph with the checkpointer and store\n",
    "graph = graph.compile(checkpointer=checkpointer, store=in_memory_store)\n",
    "```\n",
    "\n",
    "The store is then accessible in any node of the graph, as we'll see below!\n",
    "\n",
    "## Memory in LangGraph\n",
    "\n",
    "Let's take our graph used with HITL and add memory to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c67ce6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rlm/Desktop/Code/interrupt_workshop\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f600f",
   "metadata": {},
   "source": [
    "Here we set up the triage router node, which is the first node in our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38308fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/bpjxdmfx7lvd1fbdjn38y5dh0000gn/T/ipykernel_79903/45883727.py:62: UserWarning: WARNING! tool_choice is not default parameter.\n",
      "                tool_choice was transferred to model_kwargs.\n",
      "                Please confirm that tool_choice is what you intended.\n",
      "  llm = init_chat_model(\"openai:gpt-4o\", tool_choice=\"required\", temperature=0.0)\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, agent_system_prompt_hitl_memory, default_triage_instructions, default_background, default_response_preferences, default_cal_preferences\n",
    "from email_assistant.schemas import State, RouterSchema, StateInput\n",
    "from email_assistant.utils import parse_email, format_for_display, format_email_markdown, format_messages_string\n",
    "\n",
    "# Agent tools \n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: str, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    return f\"Meeting '{subject}' scheduled on {preferred_day} at {start_time} for {duration_minutes} minutes with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
    "\n",
    "@tool\n",
    "class Question(BaseModel):\n",
    "      \"\"\"Question to ask user.\"\"\"\n",
    "      content: str\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"E-mail has been sent.\"\"\"\n",
    "      done: bool\n",
    "    \n",
    "# All tools available to the agent\n",
    "tools = [\n",
    "    write_email, \n",
    "    schedule_meeting, \n",
    "    check_calendar_availability, \n",
    "    Question, \n",
    "    Done\n",
    "]\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM for use with router / structured output\n",
    "llm = init_chat_model(\"openai:gpt-4o\", temperature=0.0)\n",
    "llm_router = llm.with_structured_output(RouterSchema) \n",
    "\n",
    "# Initialize the LLM, enforcing tool use (of any available tools) for agent\n",
    "llm = init_chat_model(\"openai:gpt-4o\", tool_choice=\"required\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03538f56",
   "metadata": {},
   "source": [
    "Now, this is the critical part! We don't capture any feedback from the user in our graph. \n",
    "\n",
    "### Memory Management \n",
    "\n",
    "Let's change that by simply adding the feedback to the memory. What we *want* to do is fairly straightforward: we want to add the feedback to the memory `Store`. If we compile our graph with the store, we can access the store in any node. So that is not a problem! But we have to answer two questions: 1) how do we want the memory to be structured? 2) how do we want to update the memory? Let's create some helper functions to make this easier: we'll just store memories as string to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8aa70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory(store, namespace, default_content=None):\n",
    "    \"\"\"Get memory from the store or initialize with default if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        store: LangGraph BaseStore instance to search for existing memory\n",
    "        namespace: Tuple defining the memory namespace, e.g. (\"email_assistant\", \"triage_preferences\")\n",
    "        default_content: Default content to use if memory doesn't exist\n",
    "        \n",
    "    Returns:\n",
    "        str: The content of the memory profile, either from existing memory or the default\n",
    "    \"\"\"\n",
    "    # Search for existing memory with namespace and key\n",
    "    user_preferences = store.get(namespace, \"user_preferences\")\n",
    "    \n",
    "    # If memory exists, return its content (the value)\n",
    "    if user_preferences:\n",
    "        return user_preferences.value\n",
    "    \n",
    "    # If memory doesn't exist, add it to the store and return the default content\n",
    "    else:\n",
    "        # Namespace, key, value\n",
    "        store.put(namespace, \"user_preferences\", default_content)\n",
    "        user_preferences = default_content\n",
    "    \n",
    "    # Return the default content\n",
    "    return user_preferences \n",
    "\n",
    "class UserPreferences(BaseModel):\n",
    "    \"\"\"User preferences.\"\"\"\n",
    "    preferences: str\n",
    "    justification: str\n",
    "\n",
    "def update_memory(store, namespace, messages):\n",
    "    \"\"\"Update memory profile in the store.\n",
    "    \n",
    "    Args:\n",
    "        store: LangGraph BaseStore instance to update memory\n",
    "        namespace: Tuple defining the memory namespace, e.g. (\"email_assistant\", \"triage_preferences\")\n",
    "        messages: List of messages to update the memory with\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the existing memory\n",
    "    user_preferences = store.get(namespace, \"user_preferences\")\n",
    "    # Update the memory\n",
    "    llm = init_chat_model(\"openai:gpt-4o\", temperature=0.0).with_structured_output(UserPreferences)\n",
    "    #TODO: Still see cases of memory loss. Further prompt engineering needed, and use of o-series. \n",
    "    result = llm.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": f\"You are updating user preferences for an email assistant agent. Here are the existing user preferences related to {namespace}: {user_preferences.value}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Reflect carefully on the following messages. Use them to update the existing user preferences. IMPORTANT: Do NOT remove any existing preferences when updating the user preferences. Only add or make narrow modifications to the existing preferences. We want to ensure that we do not lose any information.\"}\n",
    "        ] + messages\n",
    "    )\n",
    "    # Save the updated memory to the store\n",
    "    store.put(namespace, \"user_preferences\", result.preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af20960",
   "metadata": {},
   "source": [
    "The triage router now leverages stored memory to make more personalized classification decisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76ef46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes \n",
    "def triage_router(state: State, store: BaseStore) -> Command[Literal[\"triage_interrupt_handler\", \"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\n",
    "\n",
    "    The triage step prevents the assistant from wasting time on:\n",
    "    - Marketing emails and spam\n",
    "    - Company-wide announcements\n",
    "    - Messages meant for other teams\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, to=to, subject=subject, email_thread=email_thread\n",
    "    )\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification  \n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Search for existing triage_preferences memory\n",
    "    triage_instructions = get_memory(store, (\"email_assistant\", \"triage_preferences\"), default_triage_instructions)\n",
    "\n",
    "    # Format system prompt with background and triage instructions\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=triage_instructions,\n",
    "    )\n",
    "\n",
    "    # Run the router LLM\n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Decision\n",
    "    classification = result.classification\n",
    "\n",
    "    # Process the classification decision\n",
    "    if classification == \"respond\":\n",
    "        print(\"ðŸ“§ Classification: RESPOND - This email requires a response\")\n",
    "        # Next node\n",
    "        goto = \"response_agent\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": result.classification,\n",
    "            \"messages\": [{\"role\": \"user\",\n",
    "                            \"content\": f\"Respond to the email: {email_markdown}\"\n",
    "                        }],\n",
    "        }\n",
    "        \n",
    "    elif classification == \"ignore\":\n",
    "        print(\"ðŸš« Classification: IGNORE - This email can be safely ignored\")\n",
    "\n",
    "        # Next node\n",
    "        goto = END\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    elif classification == \"notify\":\n",
    "        print(\"ðŸ”” Classification: NOTIFY - This email contains important information\") \n",
    "\n",
    "        # Next node\n",
    "        goto = \"triage_interrupt_handler\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {classification}\")\n",
    "    \n",
    "    return Command(goto=goto, update=update)\n",
    "\n",
    "def triage_interrupt_handler(state: State, store: BaseStore) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Handles interrupts from the triage step\"\"\"\n",
    "    \n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification  \n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Create messages\n",
    "    messages = [{\"role\": \"user\",\n",
    "                \"content\": f\"Email to notify user about: {email_markdown}\"\n",
    "                }]\n",
    "\n",
    "    # Create interrupt for Agent Inbox\n",
    "    request = {\n",
    "        \"action_request\": {\n",
    "            \"action\": f\"Email Assistant: {state['classification_decision']}\",\n",
    "            \"args\": {}\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"allow_ignore\": True,  \n",
    "            \"allow_respond\": True,\n",
    "            \"allow_edit\": False, \n",
    "            \"allow_accept\": False,  \n",
    "        },\n",
    "        # Email to show in Agent Inbox\n",
    "        \"description\": email_markdown,\n",
    "    }\n",
    "\n",
    "    # Send to Agent Inbox and wait for response\n",
    "    response = interrupt([request])[0]\n",
    "\n",
    "    # If user provides feedback, go to response agent and use feedback to respond to email   \n",
    "    if response[\"type\"] == \"response\":\n",
    "        # Add feedback to messages \n",
    "        user_input = response[\"args\"]\n",
    "        messages.append({\"role\": \"user\",\n",
    "                        \"content\": f\"User wants to reply to the email. Use this feedback to respond: {user_input}\"\n",
    "                        })\n",
    "        # Update memory with feedback\n",
    "        update_memory(store, (\"email_assistant\", \"triage_preferences\"), [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"The user decided to respond to the email, so update the triage preferences to capture this.\"\n",
    "        }] + messages)\n",
    "\n",
    "        goto = \"response_agent\"\n",
    "\n",
    "    # If user ignores email, go to END\n",
    "    elif response[\"type\"] == \"ignore\":\n",
    "        # Make note of the user's decision to ignore the email\n",
    "        messages.append({\"role\": \"user\",\n",
    "                        \"content\": f\"The user decided to ignore the email even though it was classified as notify. Update triage preferences to capture this.\"\n",
    "                        })\n",
    "        # Update memory with feedback using the memory manager\n",
    "        update_memory(store, (\"email_assistant\", \"triage_preferences\"), messages)\n",
    "        goto = END\n",
    "\n",
    "    # Catch all other responses\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid response: {response}\")\n",
    "\n",
    "    # Update the state \n",
    "    update = {\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd428f5",
   "metadata": {},
   "source": [
    "### Incorporating Memory into LLM Responses\n",
    "\n",
    "Now that we have memory managers set up, we need to use the stored preferences when generating responses. The `llm_call` function demonstrates how to retrieve and incorporate memory into the LLM's context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82b17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: State, store: BaseStore):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    # Search for existing cal_preferences memory\n",
    "    cal_preferences = get_memory(store, (\"email_assistant\", \"cal_preferences\"), default_cal_preferences)\n",
    "    \n",
    "    # Search for existing response_preferences memory\n",
    "    response_preferences = get_memory(store, (\"email_assistant\", \"response_preferences\"), default_response_preferences)\n",
    "\n",
    "    # Search for existing background memory\n",
    "    background = get_memory(store, (\"email_assistant\", \"background\"), default_background)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt_hitl_memory.format(background=background,\n",
    "                                                                                         response_preferences=response_preferences, \n",
    "                                                                                         cal_preferences=cal_preferences)}\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60aff5d",
   "metadata": {},
   "source": [
    "### Memory Integration in the Interrupt Handler\n",
    "\n",
    "The interrupt handler is where memory truly shines, as it's responsible for capturing user feedback and using it to update our various memory stores. This function showcases how we:\n",
    "\n",
    "1. **Process User Feedback**: When a user edits an email response or provides feedback, we capture that information\n",
    "2. **Update Relevant Memory**: We route the feedback to the appropriate memory manager based on the context\n",
    "3. **Learn Continuously**: Each interaction becomes a learning opportunity for the system\n",
    "\n",
    "Let's break down the key memory interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "126d3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrupt_handler(state: State, store: BaseStore):\n",
    "    \"\"\"Creates an interrupt for human review of tool calls\"\"\"\n",
    "    \n",
    "    # Store messages\n",
    "    result = []\n",
    "\n",
    "    # Iterate over the tool calls in the last message\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        \n",
    "        # Allowed tools for HITL\n",
    "        hitl_tools = [\"write_email\", \"schedule_meeting\", \"Question\"]\n",
    "        \n",
    "        # If tool is not in our HITL list, execute it directly without interruption\n",
    "        if tool_call[\"name\"] not in hitl_tools:\n",
    "\n",
    "            # Execute search_memory and other tools without interruption\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "            continue\n",
    "            \n",
    "        # Get original email from email_input in state\n",
    "        email_input = state[\"email_input\"]\n",
    "        author, to, subject, email_thread = parse_email(email_input)\n",
    "        original_email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "        \n",
    "        # Format tool call for display and prepend the original email\n",
    "        tool_display = format_for_display(state, tool_call)\n",
    "        description = original_email_markdown + tool_display\n",
    "\n",
    "        # Configure what actions are allowed in Agent Inbox\n",
    "        if tool_call[\"name\"] == \"write_email\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"Question\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": False,\n",
    "                \"allow_accept\": False,\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        # Create the interrupt request\n",
    "        request = {\n",
    "            \"action_request\": {\n",
    "                \"action\": tool_call[\"name\"],\n",
    "                \"args\": tool_call[\"args\"]\n",
    "            },\n",
    "            \"config\": config,\n",
    "            \"description\": description,\n",
    "        }\n",
    "\n",
    "        # Send to Agent Inbox and wait for response\n",
    "        response = interrupt([request])[0]\n",
    "\n",
    "        # Handle the responses \n",
    "        if response[\"type\"] == \"accept\":\n",
    "\n",
    "            # Execute the tool with original args\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "                        \n",
    "        elif response[\"type\"] == \"edit\":\n",
    "\n",
    "            # Tool selection \n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            \n",
    "            # Get edited args from Agent Inbox\n",
    "            edited_args = response[\"args\"][\"args\"]\n",
    "\n",
    "            # Save feedback in memory and update the write_email tool call with the edited content from Agent Inbox\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "\n",
    "                # Capture the initial tool call\n",
    "                initial_tool_call = tool_call[\"name\"] + \": \" + str(tool_call[\"args\"])\n",
    "\n",
    "                # Update the AI message's tool call with edited content (reference to the message in the state)\n",
    "                ai_message = state[\"messages\"][-1]\n",
    "                current_id = tool_call[\"id\"]\n",
    "                \n",
    "                # Replace the original tool call with the edited one (any changes made to this reference affect the original object in the state)\n",
    "                ai_message.tool_calls = [tc for tc in ai_message.tool_calls if tc[\"id\"] != current_id] + [\n",
    "                    {\"type\": \"tool_call\", \"name\": tool_call[\"name\"], \"args\": edited_args, \"id\": current_id}\n",
    "                ]\n",
    "                \n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "                \n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "\n",
    "                # We update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"response_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User edited the email response. Here is the initial email generated by the assistant: {initial_tool_call}. Here is the edited email: {edited_args}. Carefully examine the differences between the two. This indicates what the user modified in the email response. Update the response preferences based upon these changes so future emails generated by the assistant more closely match the user's preferences.\"\n",
    "                }])\n",
    "            \n",
    "            # Save feedback in memory and update the schedule_meeting tool call with the edited content from Agent Inbox\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "\n",
    "                # Capture the initial tool call\n",
    "                initial_tool_call = tool_call[\"name\"] + \": \" + str(tool_call[\"args\"])\n",
    "\n",
    "                # Update the AI message's tool call with edited content\n",
    "                ai_message = state[\"messages\"][-1]\n",
    "                current_id = tool_call[\"id\"]\n",
    "                \n",
    "                # Replace the original tool call with the edited one\n",
    "                ai_message.tool_calls = [tc for tc in ai_message.tool_calls if tc[\"id\"] != current_id] + [\n",
    "                    {\"type\": \"tool_call\", \"name\": tool_call[\"name\"], \"args\": edited_args, \"id\": current_id}\n",
    "                ]\n",
    "                \n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "                \n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "\n",
    "                # Update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"cal_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User edited the calendar invitation. Here is the initial calendar invitation generated by the assistant: {initial_tool_call}. Here is the edited calendar invitation: {edited_args}. Carefully examine the differences between the two. This indicates what the user modified in the calendar invitation. Update the cal preferences based upon these changes so future calendar invitations generated by the assistant more closely match the user's preferences.\"\n",
    "                }])\n",
    "            \n",
    "            # Catch all other tool calls\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        elif response[\"type\"] == \"ignore\":\n",
    "\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this email draft. Call the 'Done' tool to end the email assistant workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Update the memory by reflecting on the email tool call\n",
    "                update_memory(store, (\"email_assistant\", \"triage_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The user ignored the email draft. That means they did not want to respond to the email. Update the triage preferences to ensure emails of this type are not classified as respond.\"\n",
    "                }] + state[\"messages\"] + result)\n",
    "\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this calendar meeting draft. Call the 'Done' tool to end the email assistant workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Update the memory by reflecting on the full message history including the schedule_meeting tool call\n",
    "                update_memory(store, (\"email_assistant\", \"triage_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The user ignored the calendar meeting draft. That means they did not want to schedule a meeting for this email. Update the triage preferences to ensure emails of this type are not classified as respond.\"\n",
    "                }] + state[\"messages\"] + result)\n",
    "\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this question. Proceed with the context that you have and don't ask the user any more questions.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Update the memory by reflecting on the full message history including the Question tool call\n",
    "                update_memory(store, (\"email_assistant\", \"background\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User has provided answer to a question posed by the agent. Use this to update the background information.\"\n",
    "                }] + state[\"messages\"] + result)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        elif response[\"type\"] == \"response\":\n",
    "            # User provided feedback\n",
    "            user_feedback = response[\"args\"]\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the email. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                update_memory(store, (\"email_assistant\", \"response_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Update response preferences based upon these messages:\"\n",
    "                }] + state[\"messages\"] + result)\n",
    "\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the meeting request. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                update_memory(store, (\"email_assistant\", \"cal_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Update calendar preferences based upon these messages:\"\n",
    "                }] + state[\"messages\"] + result)\n",
    "\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User answered the question, which can we can use for any follow up actions. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                update_memory(store, (\"email_assistant\", \"background\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Update background information based upon these messages:\"\n",
    "                }] + state[\"messages\"] + result)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecedcaec",
   "metadata": {},
   "source": [
    "This is the same as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7041f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge function\n",
    "def should_continue(state: State) -> Literal[\"interrupt_handler\", END]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls: \n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"interrupt_handler\"\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes - with store parameter\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"interrupt_handler\", interrupt_handler)\n",
    "\n",
    "# Add edges\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"interrupt_handler\": \"interrupt_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"interrupt_handler\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "response_agent = agent_builder.compile()\n",
    "\n",
    "# Build overall workflow with store and checkpointer\n",
    "overall_workflow = (\n",
    "    StateGraph(State, input=StateInput)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(triage_interrupt_handler)\n",
    "    .add_node(\"response_agent\", response_agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43747219",
   "metadata": {},
   "source": [
    "## Testing the agent with memory\n",
    "\n",
    "Let's build a helper function to display the memory content so we can see how it changes as we run the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59079929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Helper function to display memory content\n",
    "def display_memory_content(store, namespace=None):\n",
    "    # Display current memory content for all namespaces\n",
    "    print(\"\\n======= CURRENT MEMORY CONTENT =======\")\n",
    "    if namespace:\n",
    "        memory = store.get(namespace, \"user_preferences\")\n",
    "        if memory:\n",
    "            print(f\"\\n--- {namespace[1]} ---\")\n",
    "            print({\"preferences\": memory.value})\n",
    "        else:\n",
    "            print(f\"\\n--- {namespace[1]} ---\")\n",
    "            print(\"No memory found\")\n",
    "    else:\n",
    "        for namespace in [\n",
    "            (\"email_assistant\", \"triage_preferences\"),\n",
    "            (\"email_assistant\", \"response_preferences\"),\n",
    "            (\"email_assistant\", \"cal_preferences\"),\n",
    "            (\"email_assistant\", \"background\")\n",
    "        ]:\n",
    "            memory = store.get(namespace, \"user_preferences\")\n",
    "            if memory:\n",
    "                print(f\"\\n--- {namespace[1]} ---\")\n",
    "                print({\"preferences\": memory.value})\n",
    "            else:\n",
    "                print(f\"\\n--- {namespace[1]} ---\")\n",
    "                print(\"No memory found\")\n",
    "            print(\"=======================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397114bf",
   "metadata": {},
   "source": [
    "## Accept `write_email` and `schedule_meeting`\n",
    "\n",
    "This test simulates an email that gets classified as \"respond\" and the agent creates a schedule_meeting and write_email tool call that the user accepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "649cee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: {'action': 'schedule_meeting', 'args': {'attendees': ['pm@client.com', 'lance@company.com'], 'subject': 'Tax Planning Strategies Discussion', 'duration_minutes': 45, 'preferred_day': '2023-11-07', 'start_time': 14}}\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "{'preferences': \"\\nEmails that are not worth responding to:\\n- Marketing newsletters and promotional emails\\n- Spam or suspicious emails\\n- CC'd on FYI threads with no direct questions\\n\\nThere are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\\n- Team member out sick or on vacation\\n- Build system notifications or deployments\\n- Project status updates without action items\\n- Important company announcements\\n- FYI emails that contain relevant information for current projects\\n- HR Department deadline reminders\\n- Subscription status / renewal reminders\\n- GitHub notifications\\n\\nEmails that are worth responding to:\\n- Direct questions from team members requiring expertise\\n- Meeting requests requiring confirmation\\n- Critical bug reports related to team's projects\\n- Requests from management requiring acknowledgment\\n- Client inquiries about project status or features\\n- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\\n- Personal reminders related to family (wife / daughter)\\n- Personal reminder related to self-care (doctor appointments, etc)\\n\"}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- response_preferences ---\n",
      "{'preferences': \"\\nUse professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\\n\\nWhen responding to technical questions that require investigation:\\n- Clearly state whether you will investigate or who you will ask\\n- Provide an estimated timeline for when you'll have more information or complete the task\\n\\nWhen responding to event or conference invitations:\\n- Always acknowledge any mentioned deadlines (particularly registration deadlines)\\n- If workshops or specific topics are mentioned, ask for more specific details about them\\n- If discounts (group or early bird) are mentioned, explicitly request information about them\\n- Don't commit \\n\\nWhen responding to collaboration or project-related requests:\\n- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\\n- Explicitly mention reviewing these materials before or during the meeting\\n- When scheduling meetings, clearly state the specific day, date, and time proposed\\n\\nWhen responding to meeting scheduling requests:\\n- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\\n- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\\n- Mention the meeting duration in your response to confirm you've noted it correctly.\\n- Reference the meeting's purpose in your response.\\n\"}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- cal_preferences ---\n",
      "{'preferences': '\\n30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- background ---\n",
      "{'preferences': \" \\nI'm Lance, a software engineer at LangChain.\\n\"}\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_1 = uuid.uuid4()\n",
    "thread_config_1 = {\"configurable\": {\"thread_id\": thread_id_1}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e199e",
   "metadata": {},
   "source": [
    "Accept the schedule_meeting tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9589423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user accepting the schedule_meeting tool call...\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: {'action': 'write_email', 'args': {'to': 'pm@client.com', 'subject': \"Re: Tax season let's schedule call\", 'content': 'Hello,\\n\\nThank you for reaching out. I have scheduled a call for us to discuss tax planning strategies on Tuesday, November 7th at 2:00 PM. The meeting is set for 45 minutes.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\nLance Martin'}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b80f99",
   "metadata": {},
   "source": [
    "Accept the write_email tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12035cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user accepting the write_email tool call...\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Done (call_XehSlrHuLUFCuusBs0LFiiFp)\n",
      " Call ID: call_XehSlrHuLUFCuusBs0LFiiFp\n",
      "  Args:\n",
      "    done: True\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "{'preferences': \"\\nEmails that are not worth responding to:\\n- Marketing newsletters and promotional emails\\n- Spam or suspicious emails\\n- CC'd on FYI threads with no direct questions\\n\\nThere are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\\n- Team member out sick or on vacation\\n- Build system notifications or deployments\\n- Project status updates without action items\\n- Important company announcements\\n- FYI emails that contain relevant information for current projects\\n- HR Department deadline reminders\\n- Subscription status / renewal reminders\\n- GitHub notifications\\n\\nEmails that are worth responding to:\\n- Direct questions from team members requiring expertise\\n- Meeting requests requiring confirmation\\n- Critical bug reports related to team's projects\\n- Requests from management requiring acknowledgment\\n- Client inquiries about project status or features\\n- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\\n- Personal reminders related to family (wife / daughter)\\n- Personal reminder related to self-care (doctor appointments, etc)\\n\"}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- response_preferences ---\n",
      "{'preferences': \"\\nUse professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\\n\\nWhen responding to technical questions that require investigation:\\n- Clearly state whether you will investigate or who you will ask\\n- Provide an estimated timeline for when you'll have more information or complete the task\\n\\nWhen responding to event or conference invitations:\\n- Always acknowledge any mentioned deadlines (particularly registration deadlines)\\n- If workshops or specific topics are mentioned, ask for more specific details about them\\n- If discounts (group or early bird) are mentioned, explicitly request information about them\\n- Don't commit \\n\\nWhen responding to collaboration or project-related requests:\\n- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\\n- Explicitly mention reviewing these materials before or during the meeting\\n- When scheduling meetings, clearly state the specific day, date, and time proposed\\n\\nWhen responding to meeting scheduling requests:\\n- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\\n- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\\n- Mention the meeting duration in your response to confirm you've noted it correctly.\\n- Reference the meeting's purpose in your response.\\n\"}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- cal_preferences ---\n",
      "{'preferences': '\\n30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'}\n",
      "=======================================\n",
      "\n",
      "\n",
      "--- background ---\n",
      "{'preferences': \" \\nI'm Lance, a software engineer at LangChain.\\n\"}\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting the write_email tool call\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc178d",
   "metadata": {},
   "source": [
    "We can look at the full messages, and the trace: \n",
    "\n",
    "https://smith.langchain.com/public/380f8bd8-0fc4-402f-9877-2a9f542b7024/r\n",
    "\n",
    "You'll notice that memory is used by the LLM but *not* updated, because we haven't any feedback via HITL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_1)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58201a21",
   "metadata": {},
   "source": [
    "## Edit `write_email` and `schedule_meeting`\n",
    "\n",
    "The agent creates a schedule_meeting and write_email tool call that the user edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac260423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: {'action': 'schedule_meeting', 'args': {'attendees': ['pm@client.com', 'lance@company.com'], 'subject': 'Tax Planning Strategies Discussion', 'duration_minutes': 45, 'preferred_day': '2023-11-07', 'start_time': 14}}\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- cal_preferences ---\n",
      "{'preferences': '\\n30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Same email as before\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_2 = uuid.uuid4()\n",
    "thread_config_2 = {\"configurable\": {\"thread_id\": thread_id_2}}\n",
    "\n",
    "# Run the graph until the first interrupt - will be classified as \"respond\" and the agent will create a write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_2):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store,(\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73ba71",
   "metadata": {},
   "source": [
    "Edit the schedule_meeting tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af760977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user editing the schedule_meeting tool call...\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: {'action': 'write_email', 'args': {'to': 'pm@client.com', 'subject': \"Re: Tax season let's schedule call\", 'content': \"Hello,\\n\\nThank you for reaching out regarding tax planning strategies. I've scheduled a call for us on Thursday, November 9th, at 2:00 PM. We'll aim for a 30-minute discussion, but we can extend if needed.\\n\\nLooking forward to your suggestions.\\n\\nBest regards,\\n\\nLance Martin\"}}\n",
      "\n",
      "Checking memory after editing schedule_meeting:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- cal_preferences ---\n",
      "{'preferences': '30 minute meetings are preferred, but 15 minute meetings are also acceptable. Meetings should preferably be scheduled on Thursdays.'}\n"
     ]
    }
   ],
   "source": [
    "# Now simulate user editing the schedule_meeting tool call\n",
    "print(\"\\nSimulating user editing the schedule_meeting tool call...\")\n",
    "edited_schedule_args = {\n",
    "    \"attendees\": [\"pm@client.com\", \"lance@company.com\"],\n",
    "    \"subject\": \"Tax Planning Discussion\",\n",
    "    \"duration_minutes\": 30,  # Changed from 45 to 30\n",
    "    \"preferred_day\": \"Thursday\",\n",
    "    \"start_time\": 14  # 2pm\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_schedule_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after editing schedule_meeting\n",
    "print(\"\\nChecking memory after editing schedule_meeting:\")\n",
    "display_memory_content(store,(\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc585a",
   "metadata": {},
   "source": [
    "See the trace: \n",
    "\n",
    "https://smith.langchain.com/public/490c2895-29a8-4b25-8f41-f0729292e4c9/r\n",
    "\n",
    "And we can see specifically the memory update: \n",
    "\n",
    "https://smith.langchain.com/public/74e0974d-6f73-4723-bb0e-d9aa8e8021bb/r\n",
    "\n",
    "Edit the write_email tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a1fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- response_preferences ---\n",
      "{'preferences': \"\\nUse professional and concise language. If the e-mail mentions a deadline, make sure to explicitly acknowledge and reference the deadline in your response.\\n\\nWhen responding to technical questions that require investigation:\\n- Clearly state whether you will investigate or who you will ask\\n- Provide an estimated timeline for when you'll have more information or complete the task\\n\\nWhen responding to event or conference invitations:\\n- Always acknowledge any mentioned deadlines (particularly registration deadlines)\\n- If workshops or specific topics are mentioned, ask for more specific details about them\\n- If discounts (group or early bird) are mentioned, explicitly request information about them\\n- Don't commit \\n\\nWhen responding to collaboration or project-related requests:\\n- Acknowledge any existing work or materials mentioned (drafts, slides, documents, etc.)\\n- Explicitly mention reviewing these materials before or during the meeting\\n- When scheduling meetings, clearly state the specific day, date, and time proposed\\n\\nWhen responding to meeting scheduling requests:\\n- If times are proposed, verify calendar availability for all time slots mentioned in the original email and then commit to one of the proposed times based on your availability by scheduling the meeting. Or, say you can't make it at the time proposed.\\n- If no times are proposed, then check your calendar for availability and propose multiple time options when available instead of selecting just one.\\n- Mention the meeting duration in your response to confirm you've noted it correctly.\\n- Reference the meeting's purpose in your response.\\n\"}\n",
      "\n",
      "Simulating user editing the write_email tool call...\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Done (call_d3o0yXTocsQU0U2pXVWEeSXn)\n",
      " Call ID: call_d3o0yXTocsQU0U2pXVWEeSXn\n",
      "  Args:\n",
      "    done: True\n",
      "\n",
      "Checking memory after editing write_email:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- response_preferences ---\n",
      "{'preferences': \"When scheduling meetings, propose a time and ask for confirmation instead of stating it as finalized. Use a more casual tone by starting with 'Thanks!' instead of 'Hello' and omitting formal sign-offs like 'Looking forward to your suggestions.'\"}\n"
     ]
    }
   ],
   "source": [
    "display_memory_content(store,(\"email_assistant\", \"response_preferences\"))\n",
    "# Now simulate user editing the write_email tool call\n",
    "print(\"\\nSimulating user editing the write_email tool call...\")\n",
    "edited_email_args = {\n",
    "    \"to\": \"pm@client.com\",\n",
    "    \"subject\": \"Re: Tax season let's schedule call\",\n",
    "    \"content\": \"Thanks! I scheduled a 30-minute call next Thursday at 3:00 PM. Would that work for you?\\n\\nBest regards,\\nLance Martin\"\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_email_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after editing write_email\n",
    "print(\"\\nChecking memory after editing write_email:\")\n",
    "display_memory_content(store,(\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbd5f9",
   "metadata": {},
   "source": [
    "Here we can see the full messages, and the trace: \n",
    "\n",
    "https://smith.langchain.com/public/2aaebf1d-5c06-4428-bc36-6b8af61259f8/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad818d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_2)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14918e",
   "metadata": {},
   "source": [
    "## Ignore `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "This tests the user ignoring write_email, schedule_meeting, and question tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d015c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n",
      "ðŸ“§ Classification: RESPOND - This email requires a response\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: {'action': 'schedule_meeting', 'args': {'attendees': ['pm@client.com', 'lance@company.com'], 'subject': 'Tax Planning Strategies Discussion', 'duration_minutes': 45, 'preferred_day': '2023-11-07', 'start_time': 14}}\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "{'preferences': \"\\nEmails that are not worth responding to:\\n- Marketing newsletters and promotional emails\\n- Spam or suspicious emails\\n- CC'd on FYI threads with no direct questions\\n\\nThere are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\\n- Team member out sick or on vacation\\n- Build system notifications or deployments\\n- Project status updates without action items\\n- Important company announcements\\n- FYI emails that contain relevant information for current projects\\n- HR Department deadline reminders\\n- Subscription status / renewal reminders\\n- GitHub notifications\\n\\nEmails that are worth responding to:\\n- Direct questions from team members requiring expertise\\n- Meeting requests requiring confirmation\\n- Critical bug reports related to team's projects\\n- Requests from management requiring acknowledgment\\n- Client inquiries about project status or features\\n- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\\n- Personal reminders related to family (wife / daughter)\\n- Personal reminder related to self-care (doctor appointments, etc)\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_3 = uuid.uuid4()\n",
    "thread_config_3 = {\"configurable\": {\"thread_id\": thread_id_3}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_3):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782e711",
   "metadata": {},
   "source": [
    "Ignore the schedule_meeting tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16c4d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulating user ignoring the schedule_meeting tool call...\n",
      "\n",
      "INTERRUPT OBJECT:\n",
      "Action Request: {'action': 'write_email', 'args': {'to': 'pm@client.com', 'subject': \"Re: Tax season let's schedule call\", 'content': 'Hello,\\n\\nThank you for reaching out regarding tax planning strategies. I am available for a call on Tuesday, November 7th at 2:00 PM for 45 minutes. Please let me know if this works for you.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\nLance Martin'}}\n",
      "\n",
      "Checking memory after ignoring first tool call:\n",
      "\n",
      "======= CURRENT MEMORY CONTENT =======\n",
      "\n",
      "--- triage_preferences ---\n",
      "{'preferences': \"Emails that are not worth responding to:\\n- Marketing newsletters and promotional emails\\n- Spam or suspicious emails\\n- CC'd on FYI threads with no direct questions\\n- Calendar meeting drafts that are ignored by the user\\n\\nThere are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\\n- Team member out sick or on vacation\\n- Build system notifications or deployments\\n- Project status updates without action items\\n- Important company announcements\\n- FYI emails that contain relevant information for current projects\\n- HR Department deadline reminders\\n- Subscription status / renewal reminders\\n- GitHub notifications\\n\\nEmails that are worth responding to:\\n- Direct questions from team members requiring expertise\\n- Meeting requests requiring confirmation\\n- Critical bug reports related to team's projects\\n- Requests from management requiring acknowledgment\\n- Client inquiries about project status or features\\n- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\\n- Personal reminders related to family (wife / daughter)\\n- Personal reminder related to self-care (doctor appointments, etc)\"}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_3):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after ignoring first tool call\n",
    "print(\"\\nChecking memory after ignoring first tool call:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67462024",
   "metadata": {},
   "source": [
    "We can look at the trace:\n",
    "\n",
    "https://smith.langchain.com/public/77602b0a-92c9-4038-b592-ac15f3d73116/r\n",
    "\n",
    "And specifically the memory update: \n",
    "\n",
    "https://smith.langchain.com/public/77602b0a-92c9-4038-b592-ac15f3d73116/r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755d5fba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_3):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after ignoring second tool call\n",
    "print(\"\\nChecking memory after ignoring second tool call:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694db9f5",
   "metadata": {},
   "source": [
    "We can see that this updates the triage preferences to reflect the fact that the user ignored the write_email tool call.\n",
    "\n",
    "https://smith.langchain.com/public/4061e6d7-23e6-43cd-aaf1-26edd3d10d72/r\n",
    "\n",
    "Look at the full message history.\n",
    "\n",
    "We can see that agent does not create a meeting and does not write the email. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272bb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_3)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597930b3",
   "metadata": {},
   "source": [
    "Now let's try an email that calls the `Question` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb91337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Partner <partner@home.com>\",\n",
    "    \"subject\": \"Meet Jim and Lisa for brunch in 3 weeks?\",\n",
    "    \"email_thread\": \"Hey, should we invite Jim and Lisa to brunch in 3 weeks? We could go to the new place on 17th that everyone is talking about.\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_4 = uuid.uuid4()\n",
    "thread_config_4 = {\"configurable\": {\"thread_id\": thread_id_4}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_4):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt for Question tool\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6581a",
   "metadata": {},
   "source": [
    "Ignore the question tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_4):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after ignoring Question tool\n",
    "print(\"\\nChecking memory after ignoring Question tool:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bea846",
   "metadata": {},
   "source": [
    "And just accept the write_email tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_4):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email after ignoring Question\n",
    "print(\"\\nChecking memory after accepting write_email (after ignoring Question):\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a21af",
   "metadata": {},
   "source": [
    "Look at the full message history.\n",
    "\n",
    "We can see that agent does not create a meeting and does not write the email. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca65c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_4)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92a42b",
   "metadata": {},
   "source": [
    "## Respond (with feedback) `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "This tests the user responding to write_email, schedule_meeting, and question tool calls with feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07676231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_5 = uuid.uuid4()\n",
    "thread_config_5 = {\"configurable\": {\"thread_id\": thread_id_5}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt \n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85fc45d",
   "metadata": {},
   "source": [
    "Provide feedback for the schedule_meeting tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a151f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for schedule_meeting\n",
    "print(\"\\nChecking memory after providing feedback for schedule_meeting:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088757c",
   "metadata": {},
   "source": [
    "Accept the schedule_meeting tool call after providing feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545063be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting schedule_meeting after feedback\n",
    "print(\"\\nChecking memory after accepting schedule_meeting after feedback:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ede94",
   "metadata": {},
   "source": [
    "Now provide feedback for the write_email tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Shorter and less formal. Include a closing statement about looking forward to the meeting!\"}]), config=thread_config_5):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for write_email\n",
    "print(\"\\nChecking memory after providing feedback for write_email:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b360a2",
   "metadata": {},
   "source": [
    "Accept the write_email tool call after providing feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email after feedback\n",
    "print(\"\\nChecking memory after accepting write_email after feedback:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e63cb",
   "metadata": {},
   "source": [
    "Look at the full message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_5)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed8841",
   "metadata": {},
   "source": [
    "Now let's try an email that calls the `Question` tool to provide feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e111a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Partner <partner@home.com>\",\n",
    "    \"subject\": \"Meet Jim and Lisa for brunch in 3 weeks?\",\n",
    "    \"email_thread\": \"Hey, should we invite Jim and Lisa to brunch in 3 weeks? We could go to the new place on 17th that everyone is talking about.\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_6 = uuid.uuid4()\n",
    "thread_config_6 = {\"configurable\": {\"thread_id\": thread_id_6}}\n",
    "\n",
    "# Run the graph until the first interrupt\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_6):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt for Question tool\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c540ebff",
   "metadata": {},
   "source": [
    "Provide feedback for the Question tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Yes, let's invite them, I really like brunch at Jack's, ideally before 11am.\"}]), config=thread_config_6):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for Question\n",
    "print(\"\\nChecking memory after providing feedback for Question:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9dbba1",
   "metadata": {},
   "source": [
    "Accept the write_email tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_6):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email after answering Question\n",
    "print(\"\\nChecking memory after accepting write_email after answering Question:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ed860",
   "metadata": {},
   "source": [
    "Look at the full message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61fab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_6)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b11d0c",
   "metadata": {},
   "source": [
    "## Test Case for Notify Classification\n",
    "\n",
    "This test simulates an email that gets classified as \"notify\" and the user decides to respond with feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notify - Important FYI Email\n",
    "email_input_notify = {\n",
    "    \"to\": \"Team Members <team@company.com>\",\n",
    "    \"author\": \"IT Department <it@company.com>\",\n",
    "    \"subject\": \"Critical Security Update\",\n",
    "    \"email_thread\": \"Dear Team,\\n\\nThis is an important security notification. We will be updating our authentication system this weekend. During the update window (Saturday 2am-4am), you will not be able to access company resources.\\n\\nPlease ensure you log out of all systems before the maintenance window.\\n\\nRegards,\\nIT Department\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_7 = uuid.uuid4()\n",
    "thread_config_7 = {\"configurable\": {\"thread_id\": thread_id_7}}\n",
    "\n",
    "# Run the graph until the first interrupt - should be classified as \"notify\"\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_notify}, config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt for Notify\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02f3be",
   "metadata": {},
   "source": [
    "Now simulate user deciding to respond with feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510235cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating user deciding to respond with feedback...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"We should acknowledge receipt of this important notice and confirm that we'll be logged out before the maintenance window.\"}]), config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after responding with feedback to Notify\n",
    "print(\"\\nChecking memory after responding with feedback to Notify:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b1139",
   "metadata": {},
   "source": [
    "Accept the write_email tool call after feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email for Notify\n",
    "print(\"\\nChecking memory after accepting write_email for Notify:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878373b",
   "metadata": {},
   "source": [
    "Look at the full message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_7)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e48281",
   "metadata": {},
   "source": [
    "## Test Case for Notify + Ignore\n",
    "\n",
    "This test simulates an email that gets classified as \"notify\" and the user decides to ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notify - Important FYI Email\n",
    "email_input_notify = {\n",
    "    \"to\": \"Team Members <team@company.com>\",\n",
    "    \"author\": \"HR Department <hr@company.com>\",\n",
    "    \"subject\": \"Company Picnic Next Month\",\n",
    "    \"email_thread\": \"Dear Team,\\n\\nWe're planning the annual company picnic for next month. The tentative date is Saturday, June 15th from noon to 4pm at Central Park. There will be food, games, and activities for families.\\n\\nMore details will follow in the coming weeks.\\n\\nRegards,\\nHR Department\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_8 = uuid.uuid4()\n",
    "thread_config_8 = {\"configurable\": {\"thread_id\": thread_id_8}}\n",
    "\n",
    "# Run the graph until the first interrupt - should be classified as \"notify\"\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_notify}, config=thread_config_8):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt for Notify + Ignore\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a8c79",
   "metadata": {},
   "source": [
    "Now simulate user deciding to ignore the notification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating user deciding to ignore the notification...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_8):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after ignoring Notify\n",
    "print(\"\\nChecking memory after ignoring Notify:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05136d96",
   "metadata": {},
   "source": [
    "Look at the full message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f3f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_8)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075a3ea",
   "metadata": {},
   "source": [
    "## Testing with Local Deployment\n",
    "\n",
    "You can find this graph in the `src/email_assistant` directory:\n",
    "\n",
    "* `src/email_assistant/email_assistant_hitl_memory.py`\n",
    "\n",
    "You can test it locally in LangGraph Studio by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60fa538",
   "metadata": {},
   "outputs": [],
   "source": [
    "! langgraph dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6319d",
   "metadata": {},
   "source": [
    "![inbox](img/agent-inbox-edit.png)\n",
    "\n",
    "As you provide feedback or edit replies, you can see memories accumulate in the `memory` tab in LangGraph Studio.\n",
    "\n",
    "![studio-img](img/memory-studio.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
